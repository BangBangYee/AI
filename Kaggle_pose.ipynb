{"cells":[{"cell_type":"markdown","metadata":{"id":"N91VkiiGUarG"},"source":["## 필요 라이브러리 설치"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3670,"status":"ok","timestamp":1733796547289,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"9wav3uH4grrl","outputId":"28e0280d-056c-4456-d3f9-01269a85188b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.48-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.48-py3-none-any.whl (898 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.8/898.8 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.48 ultralytics-thop-2.0.13\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4630,"status":"ok","timestamp":1733796551915,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"BOIOgDqMguQe","outputId":"1a923405-8c05-418b-d5bf-17a02de81a8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.20)\n","Collecting albumentations\n","  Downloading albumentations-1.4.22-py3-none-any.whl.metadata (33 kB)\n","Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n","Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.10.3)\n","Collecting albucore==0.0.21 (from albumentations)\n","  Downloading albucore-0.0.21-py3-none-any.whl.metadata (5.3 kB)\n","Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.21->albumentations) (3.11.0)\n","Collecting simsimd>=5.9.2 (from albucore==0.0.21->albumentations)\n","  Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (2.27.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n","Downloading albumentations-1.4.22-py3-none-any.whl (258 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading albucore-0.0.21-py3-none-any.whl (12 kB)\n","Downloading simsimd-6.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (632 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: simsimd, albucore, albumentations\n","  Attempting uninstall: albucore\n","    Found existing installation: albucore 0.0.19\n","    Uninstalling albucore-0.0.19:\n","      Successfully uninstalled albucore-0.0.19\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 1.4.20\n","    Uninstalling albumentations-1.4.20:\n","      Successfully uninstalled albumentations-1.4.20\n","Successfully installed albucore-0.0.21 albumentations-1.4.22 simsimd-6.2.1\n"]}],"source":["!pip install -U albumentations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3893,"status":"ok","timestamp":1733796555804,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"Ns-_kosJgwki","outputId":"bb18c881-ac3b-40cd-e624-921131553067"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: albumentations[imgaug] in /usr/local/lib/python3.10/dist-packages (1.4.22)\n","\u001b[33mWARNING: albumentations 1.4.22 does not provide the extra 'imgaug'\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (1.26.4)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (1.13.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (6.0.2)\n","Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (2.10.3)\n","Requirement already satisfied: albucore==0.0.21 in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (0.0.21)\n","Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (0.2.0)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (4.10.0.84)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.21->albumentations[imgaug]) (3.11.0)\n","Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.21->albumentations[imgaug]) (6.2.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations[imgaug]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations[imgaug]) (2.27.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations[imgaug]) (4.12.2)\n","Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.22)\n","Collecting pytorch\n","  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n","Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.10.3)\n","Requirement already satisfied: albucore==0.0.21 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.21)\n","Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.21->albumentations) (3.11.0)\n","Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.21->albumentations) (6.2.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (2.27.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n","Building wheels for collected packages: pytorch\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n","Failed to build pytorch\n","\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch)\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install albumentations[imgaug]\n","!pip install -U albumentations pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2753,"status":"ok","timestamp":1733796558552,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"dvk0nHougzWE","outputId":"c8e151be-4b47-47ad-bed5-c181a82a1066"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"]}],"source":["!pip install torch torchvision torchaudio\n"]},{"cell_type":"markdown","metadata":{"id":"0S9ApXP-Uf8p"},"source":["## 학습 데이터 로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAbJxwwZgi18"},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1733795615179,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"DUF3VCPvgU1s","outputId":"a9c7277c-9d7f-4e30-b27b-823aea9db4db"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Images: /content/drive/MyDrive/Seg_dataset/images/train\n","Validation Images: /content/drive/MyDrive/Seg_dataset/images/val\n","Train Labels: /content/drive/MyDrive/Seg_dataset/labels/train\n","Validation Labels: /content/drive/MyDrive/Seg_dataset/labels/val\n"]}],"source":["# 데이터 경로 설정\n","base_dir = '/content/drive/MyDrive/Seg_dataset'\n","\n","train_images_dir = f\"{base_dir}/images/train\"\n","val_images_dir = f\"{base_dir}/images/val\"\n","train_labels_dir = f\"{base_dir}/labels/train\"\n","val_labels_dir = f\"{base_dir}/labels/val\"\n","\n","# 데이터 경로 출력\n","print(f\"Train Images: {train_images_dir}\")\n","print(f\"Validation Images: {val_images_dir}\")\n","print(f\"Train Labels: {train_labels_dir}\")\n","print(f\"Validation Labels: {val_labels_dir}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19626,"status":"ok","timestamp":1733795793371,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"F36qtGTEglVK","outputId":"26e8b914-2afd-43d5-a7f7-c3d903aecaff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Images: 894, Train Labels: 894\n","Validation Images: 256, Validation Labels: 256\n"]}],"source":["# 파일 개수를 확인하는 함수\n","def count_files_in_directory(directory, extensions=None):\n","    if os.path.exists(directory):\n","        return len([file for file in os.listdir(directory) if not extensions or file.endswith(extensions)])\n","    else:\n","        return 0\n","\n","# 이미지와 레이블 파일 개수 확인\n","train_images_count = count_files_in_directory(train_images_dir, ('.jpg', '.jpeg', '.png'))\n","val_images_count = count_files_in_directory(val_images_dir, ('.jpg', '.jpeg', '.png'))\n","train_labels_count = count_files_in_directory(train_labels_dir, ('.txt',))\n","val_labels_count = count_files_in_directory(val_labels_dir, ('.txt',))\n","\n","print(f\"Train Images: {train_images_count}, Train Labels: {train_labels_count}\")\n","print(f\"Validation Images: {val_images_count}, Validation Labels: {val_labels_count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":414,"status":"ok","timestamp":1733795795706,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"PKdd1Kp4gpU4","outputId":"97e3ca53-6160-43b5-bdc1-94d9a041cfc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["YAML 파일 생성 완료: /content/custom_data.yaml\n"]}],"source":["# YAML 파일 생성\n","data_yaml = f\"\"\"\n","train: {train_images_dir}\n","val: {val_images_dir}\n","\n","nc: 2  # 클래스 개수\n","names: ['person', 'bed']  # 클래스 이름\n","\"\"\"\n","\n","# YAML 파일 저장\n","yaml_path = '/content/custom_data.yaml'\n","with open(yaml_path, 'w') as f:\n","    f.write(data_yaml)\n","\n","print(f\"YAML 파일 생성 완료: {yaml_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"aGU_qT5XUscx"},"source":["## 모델 학습 및 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1257145,"status":"ok","timestamp":1733733920736,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"4XPinQbrg18y","outputId":"2468f747-2861-4e29-aa60-df3d99070cfb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-seg.pt to 'yolov8n-seg.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6.74M/6.74M [00:00<00:00, 337MB/s]"]},{"name":"stdout","output_type":"stream","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 6.52M/6.52M [00:00<00:00, 395MB/s]"]},{"name":"stdout","output_type":"stream","text":["Ultralytics 8.3.48 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=/content/custom_data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=custom_seg_model, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/custom_seg_model\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 755k/755k [00:00<00:00, 102MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1   1004470  ultralytics.nn.modules.head.Segment          [2, 32, 64, [64, 128, 256]]   \n","YOLOv8n-seg summary: 261 layers, 3,264,006 parameters, 3,263,990 gradients, 12.1 GFLOPs\n","\n","Transferred 381/417 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/custom_seg_model', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5.35M/5.35M [00:00<00:00, 307MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Seg_dataset/labels/train.cache... 894 images, 0 backgrounds, 0 corrupt: 100%|██████████| 894/894 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Seg_dataset/labels/val.cache... 256 images, 0 backgrounds, 0 corrupt: 100%|██████████| 256/256 [00:00<?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to runs/segment/custom_seg_model/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/segment/custom_seg_model\u001b[0m\n","Starting training for 100 epochs...\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      1/100      3.08G      1.177      3.155      2.257      1.452        109        640: 100%|██████████| 56/56 [00:37<00:00,  1.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:09<00:00,  1.16s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.452      0.374      0.315      0.166      0.457      0.331      0.288      0.134\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      2/100      2.83G      1.312      3.199      1.937      1.558        132        640: 100%|██████████| 56/56 [00:09<00:00,  6.09it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.68it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.388      0.364      0.292      0.131       0.33      0.312      0.232      0.086\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      3/100       2.9G      1.369      3.375      1.951      1.585        107        640: 100%|██████████| 56/56 [00:08<00:00,  6.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.74it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.323      0.325      0.244     0.0999      0.291      0.294      0.205      0.071\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      4/100       2.9G       1.41      3.444      1.945      1.618        106        640: 100%|██████████| 56/56 [00:09<00:00,  6.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.75it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.429      0.353        0.3      0.128      0.333      0.244      0.186     0.0631\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      5/100      2.86G      1.389      3.363      1.909       1.62        124        640: 100%|██████████| 56/56 [00:08<00:00,  6.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.81it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.392      0.349      0.298       0.13      0.381      0.282      0.236     0.0845\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      6/100      2.87G      1.358      3.319      1.877      1.594        182        640: 100%|██████████| 56/56 [00:08<00:00,  6.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.81it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.442      0.379      0.334       0.16      0.367      0.321      0.263      0.109\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      7/100       2.9G      1.343      3.263      1.835      1.575        118        640: 100%|██████████| 56/56 [00:09<00:00,  6.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.412      0.369       0.33      0.159      0.358      0.327      0.269      0.105\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      8/100      2.83G      1.305      3.134      1.759      1.556        115        640: 100%|██████████| 56/56 [00:09<00:00,  6.11it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.92it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.438      0.389      0.343      0.175      0.424      0.327      0.294      0.132\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      9/100      2.89G      1.287      3.206       1.76      1.541        104        640: 100%|██████████| 56/56 [00:09<00:00,  6.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.65it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.313      0.374      0.273      0.125      0.297      0.292      0.211     0.0828\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     10/100      2.98G      1.255      3.103      1.715      1.518         94        640: 100%|██████████| 56/56 [00:08<00:00,  6.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.06it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.388      0.367      0.293      0.141      0.309      0.297      0.209     0.0803\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     11/100      2.97G      1.269      3.073      1.705      1.525        113        640: 100%|██████████| 56/56 [00:09<00:00,  6.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.97it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.408      0.409      0.355      0.183      0.347       0.34      0.266      0.112\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     12/100      2.87G      1.235      3.004      1.657      1.493        111        640: 100%|██████████| 56/56 [00:09<00:00,  6.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.461      0.424      0.393      0.207      0.429       0.38      0.331      0.149\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     13/100      2.88G      1.215      2.947      1.638      1.497        107        640: 100%|██████████| 56/56 [00:09<00:00,  6.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.74it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.474      0.443      0.388        0.2       0.43      0.397      0.326      0.137\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     14/100      2.89G      1.201      2.874      1.606       1.48        100        640: 100%|██████████| 56/56 [00:09<00:00,  6.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.01it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.514      0.428      0.429      0.234      0.491      0.381      0.374      0.174\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     15/100      2.96G      1.192      2.834       1.56      1.463         97        640: 100%|██████████| 56/56 [00:09<00:00,  6.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.89it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.499      0.457      0.418      0.223      0.452      0.407       0.35      0.156\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     16/100      2.86G      1.213      2.896      1.583       1.47         85        640: 100%|██████████| 56/56 [00:09<00:00,  6.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.73it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.519      0.418      0.403      0.208      0.431      0.392      0.328      0.143\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     17/100      2.94G      1.204      2.857      1.566      1.474        103        640: 100%|██████████| 56/56 [00:09<00:00,  6.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.97it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.464      0.434      0.391      0.211       0.41      0.388      0.322      0.147\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     18/100      2.93G      1.194       2.81      1.555       1.46        125        640: 100%|██████████| 56/56 [00:09<00:00,  6.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.92it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.563       0.43      0.439      0.238      0.512       0.39      0.374      0.167\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     19/100      2.85G      1.159      2.781       1.53      1.437         95        640: 100%|██████████| 56/56 [00:09<00:00,  6.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.85it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.496      0.464      0.443      0.244      0.482      0.437      0.408      0.192\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     20/100      2.85G      1.155      2.772        1.5      1.449         77        640: 100%|██████████| 56/56 [00:08<00:00,  6.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.80it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926       0.54      0.451      0.447      0.234      0.511      0.398      0.373      0.173\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     21/100      2.89G      1.149      2.742      1.489      1.442         95        640: 100%|██████████| 56/56 [00:09<00:00,  6.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.03it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.525      0.475      0.473      0.253      0.516      0.403      0.411      0.191\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     22/100      2.87G      1.118      2.686      1.448      1.424        102        640: 100%|██████████| 56/56 [00:09<00:00,  6.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.533      0.447      0.436      0.232      0.519      0.402      0.377      0.163\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     23/100      2.93G      1.126      2.661      1.452      1.433        115        640: 100%|██████████| 56/56 [00:08<00:00,  6.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.79it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.497      0.486      0.453       0.25      0.507      0.426      0.411      0.186\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     24/100      2.87G      1.116      2.697      1.443      1.407        109        640: 100%|██████████| 56/56 [00:09<00:00,  6.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.504      0.477      0.451      0.253      0.561      0.396      0.413      0.191\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     25/100      2.84G      1.109      2.645      1.411      1.409        112        640: 100%|██████████| 56/56 [00:09<00:00,  6.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.96it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.515      0.454      0.451       0.25      0.483      0.429      0.399      0.185\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     26/100      2.89G      1.116      2.709      1.431      1.416        123        640: 100%|██████████| 56/56 [00:08<00:00,  6.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.81it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.524      0.483      0.459      0.254      0.486      0.465      0.413      0.193\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     27/100      2.97G      1.078        2.6      1.366      1.387         99        640: 100%|██████████| 56/56 [00:08<00:00,  6.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.537      0.473      0.465      0.262       0.51      0.429      0.399      0.195\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     28/100      2.87G      1.089      2.558       1.35      1.381        101        640: 100%|██████████| 56/56 [00:09<00:00,  6.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.547      0.415      0.452       0.25      0.416      0.445      0.383      0.179\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     29/100      2.88G      1.091       2.63      1.358      1.385        117        640: 100%|██████████| 56/56 [00:09<00:00,  6.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.87it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.544      0.439      0.438      0.246      0.499      0.388      0.367      0.172\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     30/100      2.93G      1.078      2.489      1.347      1.381        158        640: 100%|██████████| 56/56 [00:08<00:00,  6.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.83it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.585      0.449      0.487      0.279      0.541      0.422      0.439      0.213\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     31/100      2.85G      1.057      2.509      1.303      1.375        116        640: 100%|██████████| 56/56 [00:09<00:00,  6.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.15it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.543       0.49      0.464      0.253      0.511      0.458      0.419      0.183\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     32/100      2.93G      1.063      2.499      1.303      1.363        109        640: 100%|██████████| 56/56 [00:08<00:00,  6.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.88it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.632      0.463      0.513      0.298      0.553      0.452      0.447      0.227\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     33/100       2.9G      1.064      2.479      1.311      1.368        134        640: 100%|██████████| 56/56 [00:08<00:00,  6.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.87it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.575      0.465      0.478      0.271      0.544      0.439      0.437      0.215\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     34/100      2.88G      1.026      2.416      1.269      1.335        125        640: 100%|██████████| 56/56 [00:09<00:00,  6.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.98it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.557      0.485       0.49      0.279      0.521      0.434      0.419      0.205\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     35/100      2.86G      1.043       2.44      1.266      1.352        109        640: 100%|██████████| 56/56 [00:09<00:00,  6.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926       0.54      0.481      0.479      0.263      0.483      0.431      0.396      0.188\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     36/100      2.91G      1.017      2.445      1.251      1.339        103        640: 100%|██████████| 56/56 [00:08<00:00,  6.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.72it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.588      0.445      0.469      0.259      0.569      0.432      0.429      0.199\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     37/100      2.97G      1.035      2.392      1.265      1.347        102        640: 100%|██████████| 56/56 [00:08<00:00,  6.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.84it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.585      0.475      0.495      0.276       0.54      0.457       0.44      0.213\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     38/100      2.86G      1.018      2.327      1.224      1.335        119        640: 100%|██████████| 56/56 [00:09<00:00,  6.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.03it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.575      0.504      0.477      0.272       0.51      0.477      0.419      0.202\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     39/100      2.93G      1.017      2.383      1.222      1.331        105        640: 100%|██████████| 56/56 [00:09<00:00,  6.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.88it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.542      0.501      0.487      0.289      0.517      0.476      0.443      0.218\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     40/100      2.88G      1.006      2.291      1.198      1.312        161        640: 100%|██████████| 56/56 [00:08<00:00,  6.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.78it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.605      0.485      0.505       0.29      0.571      0.449      0.444      0.219\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     41/100      2.91G     0.9941      2.291      1.198      1.316        105        640: 100%|██████████| 56/56 [00:08<00:00,  6.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.571      0.513      0.526      0.307      0.593      0.456      0.482      0.245\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     42/100      2.87G     0.9787      2.264      1.172      1.301        100        640: 100%|██████████| 56/56 [00:09<00:00,  6.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.533      0.491      0.486      0.285      0.514      0.472      0.444      0.229\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     43/100       2.9G     0.9755      2.267      1.153        1.3         94        640: 100%|██████████| 56/56 [00:08<00:00,  6.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.90it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.537      0.485      0.466      0.274      0.527      0.457      0.442      0.222\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     44/100      2.91G     0.9688      2.318      1.158      1.303        103        640: 100%|██████████| 56/56 [00:09<00:00,  6.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.554      0.495      0.481      0.277       0.53      0.475      0.444      0.221\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     45/100      2.92G     0.9786      2.258      1.163      1.299        100        640: 100%|██████████| 56/56 [00:09<00:00,  6.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.15it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.617      0.508      0.521      0.312      0.581      0.473      0.466      0.229\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     46/100      2.92G     0.9636      2.232      1.121      1.291         87        640: 100%|██████████| 56/56 [00:08<00:00,  6.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.633       0.46      0.496      0.295        0.6      0.439       0.45      0.228\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     47/100      2.91G     0.9542      2.238       1.12       1.29        128        640: 100%|██████████| 56/56 [00:08<00:00,  6.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.04it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.568      0.528      0.511      0.313      0.571       0.47      0.455      0.231\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     48/100      2.88G     0.9613      2.263      1.128      1.294        111        640: 100%|██████████| 56/56 [00:09<00:00,  6.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.04it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.569      0.467      0.468      0.275      0.542      0.443      0.413      0.199\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     49/100       2.9G     0.9411      2.225       1.11      1.282         96        640: 100%|██████████| 56/56 [00:09<00:00,  6.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.89it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.588      0.486      0.515      0.308      0.556      0.462      0.448      0.234\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     50/100      2.84G     0.9531      2.192      1.096      1.277        111        640: 100%|██████████| 56/56 [00:08<00:00,  6.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.649      0.481      0.507      0.305      0.637      0.453      0.454      0.228\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     51/100      2.89G     0.9377      2.161      1.097      1.275        119        640: 100%|██████████| 56/56 [00:09<00:00,  6.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.98it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.585      0.485      0.502      0.301      0.567      0.464      0.456      0.236\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     52/100      2.89G     0.9342      2.153      1.074      1.266        118        640: 100%|██████████| 56/56 [00:09<00:00,  6.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.641      0.465      0.498      0.296      0.608      0.439      0.445      0.232\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     53/100      2.92G     0.9294       2.15      1.085      1.263        108        640: 100%|██████████| 56/56 [00:08<00:00,  6.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.95it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.534      0.513      0.478      0.287      0.508      0.485      0.442      0.219\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     54/100      2.96G     0.9154      2.124      1.041      1.258        102        640: 100%|██████████| 56/56 [00:08<00:00,  6.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.02it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.598       0.49      0.496      0.303      0.569      0.461      0.444      0.232\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     55/100      2.94G     0.8852      2.073      1.017      1.236         97        640: 100%|██████████| 56/56 [00:09<00:00,  6.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.584      0.517      0.497      0.298      0.575      0.502       0.48      0.242\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     56/100      2.95G     0.9227      2.088      1.045      1.258         93        640: 100%|██████████| 56/56 [00:09<00:00,  6.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.66it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.663      0.486      0.528      0.319      0.631      0.467      0.489      0.252\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     57/100      2.83G     0.9205      2.144      1.039      1.254         99        640: 100%|██████████| 56/56 [00:09<00:00,  6.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.04it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.552      0.493      0.467      0.278      0.527      0.454      0.423      0.219\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     58/100      2.87G     0.9151      2.107      1.021      1.256        118        640: 100%|██████████| 56/56 [00:09<00:00,  6.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.04it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.574       0.51      0.504      0.296      0.543      0.484      0.449      0.226\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     59/100      2.94G     0.8988      2.064       1.02      1.248        126        640: 100%|██████████| 56/56 [00:09<00:00,  6.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.90it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.635      0.468      0.508      0.297      0.628      0.442      0.465      0.235\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     60/100      2.86G      0.909      2.072      1.023      1.246        114        640: 100%|██████████| 56/56 [00:08<00:00,  6.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  4.00it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.653      0.451      0.496      0.296      0.593      0.462      0.452      0.225\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     61/100      2.88G     0.8952      2.046      1.004      1.244        118        640: 100%|██████████| 56/56 [00:09<00:00,  6.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.88it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.607      0.482        0.5      0.297      0.575      0.469      0.457      0.226\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     62/100      2.87G     0.8896      2.062       1.01      1.243        103        640: 100%|██████████| 56/56 [00:09<00:00,  5.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.93it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926        0.6      0.501      0.515      0.304      0.557      0.503      0.472       0.24\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     63/100       2.9G     0.8767      2.022     0.9929      1.234        106        640: 100%|██████████| 56/56 [00:08<00:00,  6.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.91it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.657      0.449      0.498      0.307      0.636      0.437      0.466      0.249\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     64/100      2.85G      0.859      1.999     0.9599      1.215        127        640: 100%|██████████| 56/56 [00:08<00:00,  6.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.12it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.632      0.455      0.507      0.309      0.605      0.436      0.462      0.237\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     65/100      2.89G     0.8697      2.029     0.9591      1.215        123        640: 100%|██████████| 56/56 [00:09<00:00,  5.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.92it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.623      0.507      0.528      0.321      0.609      0.482      0.482      0.251\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     66/100      2.88G     0.8462      1.976     0.9372      1.212         97        640: 100%|██████████| 56/56 [00:08<00:00,  6.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.84it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.634      0.504      0.524      0.317      0.593      0.486      0.483      0.255\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     67/100      2.86G     0.8581      1.916     0.9297      1.209        121        640: 100%|██████████| 56/56 [00:08<00:00,  6.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.97it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.574      0.511      0.502      0.307      0.604      0.459       0.46      0.241\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     68/100      2.96G      0.838      1.932     0.9168      1.196         78        640: 100%|██████████| 56/56 [00:09<00:00,  6.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.18it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.622      0.505      0.514      0.311      0.588      0.482      0.467      0.236\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     69/100      2.87G     0.8723      1.962     0.9553      1.213        117        640: 100%|██████████| 56/56 [00:09<00:00,  6.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.94it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.653      0.477       0.52      0.312       0.57      0.483      0.464      0.243\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     70/100      2.87G      0.849      1.912     0.9197      1.207        123        640: 100%|██████████| 56/56 [00:08<00:00,  6.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  4.00it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.634      0.502      0.524      0.313      0.617      0.478      0.483       0.25\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     71/100      2.87G      0.833      1.914     0.9149      1.201        127        640: 100%|██████████| 56/56 [00:09<00:00,  6.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.17it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.607      0.522      0.535      0.319      0.586      0.488      0.483      0.254\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     72/100      2.89G     0.8344      1.937     0.9128      1.198        109        640: 100%|██████████| 56/56 [00:09<00:00,  6.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.87it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.603      0.522      0.534      0.329      0.579      0.488      0.486      0.258\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     73/100      3.02G     0.8406      1.903     0.9039      1.203        128        640: 100%|██████████| 56/56 [00:08<00:00,  6.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.91it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.634      0.485       0.52      0.319      0.615      0.457      0.471      0.251\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     74/100      2.88G     0.8143      1.852     0.8741      1.179        132        640: 100%|██████████| 56/56 [00:09<00:00,  6.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.87it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.622      0.503       0.53      0.329      0.603      0.482       0.49      0.263\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     75/100       2.9G     0.8142      1.856     0.8769      1.186        139        640: 100%|██████████| 56/56 [00:09<00:00,  6.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.15it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.704      0.481      0.542      0.326      0.626       0.49      0.504      0.262\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     76/100      2.85G     0.8262      1.848     0.8799      1.189        122        640: 100%|██████████| 56/56 [00:09<00:00,  6.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.85it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.607      0.528      0.529       0.33      0.605      0.502      0.493      0.268\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     77/100      2.84G     0.8202      1.844     0.8886      1.192        114        640: 100%|██████████| 56/56 [00:09<00:00,  6.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.615      0.523      0.536      0.327       0.61      0.478      0.485      0.262\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     78/100      2.93G     0.8035      1.819     0.8509      1.172        125        640: 100%|██████████| 56/56 [00:09<00:00,  6.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.99it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.608      0.534      0.544       0.33      0.617      0.503      0.504      0.265\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     79/100      2.91G        0.8      1.817      0.865      1.179        122        640: 100%|██████████| 56/56 [00:09<00:00,  6.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.89it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.651      0.496      0.523      0.323      0.628      0.482      0.482      0.259\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     80/100      2.81G     0.7905      1.789     0.8351      1.161        121        640: 100%|██████████| 56/56 [00:08<00:00,  6.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.03it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926       0.65      0.507      0.526      0.328      0.666       0.47      0.497      0.268\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     81/100      2.91G        0.8      1.798     0.8515      1.171        116        640: 100%|██████████| 56/56 [00:09<00:00,  6.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.20it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.625      0.505      0.514      0.313      0.608      0.479      0.473      0.249\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     82/100      2.85G     0.7998      1.803     0.8561      1.182        104        640: 100%|██████████| 56/56 [00:09<00:00,  6.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.65it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.629      0.531      0.535      0.326      0.591      0.504      0.491      0.263\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     83/100      2.86G     0.7993      1.812     0.8367      1.167        134        640: 100%|██████████| 56/56 [00:08<00:00,  6.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.03it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.605      0.524      0.517      0.317      0.607       0.49       0.48      0.254\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     84/100      2.87G     0.7812      1.789     0.8203      1.161        133        640: 100%|██████████| 56/56 [00:09<00:00,  6.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.09it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.596      0.533      0.522      0.323      0.579      0.518      0.476      0.256\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     85/100      2.92G     0.7813      1.777     0.8177       1.15         95        640: 100%|██████████| 56/56 [00:09<00:00,  6.09it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.05it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.639      0.507      0.526      0.321      0.603      0.496      0.487      0.261\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     86/100      2.88G     0.7755      1.756     0.8167      1.153         92        640: 100%|██████████| 56/56 [00:08<00:00,  6.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.88it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.599      0.524      0.513      0.315      0.591      0.497      0.478      0.255\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     87/100      2.92G     0.7784       1.73     0.8205      1.155        105        640: 100%|██████████| 56/56 [00:08<00:00,  6.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.627      0.505      0.524       0.32      0.632      0.466      0.481      0.262\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     88/100      2.89G     0.7662      1.752     0.8002      1.154        118        640: 100%|██████████| 56/56 [00:09<00:00,  6.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.06it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.665      0.481      0.524      0.318      0.624      0.479      0.478      0.254\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     89/100         3G     0.7701      1.726     0.7983      1.153        104        640: 100%|██████████| 56/56 [00:08<00:00,  6.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.98it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.645      0.499      0.528      0.325      0.665      0.471      0.495      0.266\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     90/100      3.04G     0.7777       1.79     0.8078      1.149        101        640: 100%|██████████| 56/56 [00:08<00:00,  6.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.15it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.649      0.491      0.528      0.326      0.647      0.466      0.493      0.267\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     91/100       2.9G     0.7206      1.541     0.7573      1.105         44        640: 100%|██████████| 56/56 [00:10<00:00,  5.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.646      0.497      0.507      0.302      0.611      0.484      0.467      0.242\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     92/100      2.71G     0.6804       1.45     0.6429      1.086         51        640: 100%|██████████| 56/56 [00:08<00:00,  6.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.04it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.667      0.501      0.532      0.323      0.641      0.481       0.49      0.257\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     93/100      2.72G     0.6747      1.437     0.6239      1.095         52        640: 100%|██████████| 56/56 [00:08<00:00,  6.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.96it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.663      0.503      0.524      0.326      0.636      0.496      0.491      0.265\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     94/100      2.73G     0.6702      1.398     0.6053      1.092         44        640: 100%|██████████| 56/56 [00:08<00:00,  6.50it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.97it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.653      0.515      0.542      0.338      0.638      0.502      0.512      0.278\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     95/100      2.68G     0.6557      1.397     0.5928      1.076         38        640: 100%|██████████| 56/56 [00:08<00:00,  6.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.98it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.679      0.505      0.537      0.333      0.637      0.506      0.506      0.272\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     96/100      2.72G     0.6384      1.376      0.576      1.059         40        640: 100%|██████████| 56/56 [00:08<00:00,  6.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.87it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.692      0.484      0.545      0.336      0.672       0.47      0.511      0.279\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     97/100      2.65G     0.6443      1.382      0.574      1.066         39        640: 100%|██████████| 56/56 [00:08<00:00,  6.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.17it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926       0.67      0.504      0.543      0.331      0.598      0.519      0.501      0.272\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     98/100      2.69G     0.6288      1.342     0.5716      1.058         46        640: 100%|██████████| 56/56 [00:08<00:00,  6.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.91it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.605      0.534      0.541      0.334      0.632      0.487      0.501      0.272\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["     99/100      2.69G     0.6314       1.35      0.562      1.054         52        640: 100%|██████████| 56/56 [00:08<00:00,  6.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.10it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.668       0.51      0.543      0.336      0.657      0.493      0.508      0.273\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["    100/100      2.69G     0.6452      1.373     0.5722      1.068         44        640: 100%|██████████| 56/56 [00:08<00:00,  6.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:01<00:00,  4.08it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.691      0.492      0.543      0.337      0.679      0.492      0.512      0.277\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","100 epochs completed in 0.337 hours.\n","Optimizer stripped from runs/segment/custom_seg_model/weights/last.pt, 6.8MB\n","Optimizer stripped from runs/segment/custom_seg_model/weights/best.pt, 6.8MB\n","\n","Validating runs/segment/custom_seg_model/weights/best.pt...\n","Ultralytics 8.3.48 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","YOLOv8n-seg summary (fused): 195 layers, 3,258,454 parameters, 0 gradients, 12.0 GFLOPs\n"]},{"name":"stderr","output_type":"stream","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        256        926      0.653      0.515      0.542      0.337      0.636      0.503      0.512      0.278\n","                person        256        495      0.712      0.576      0.606       0.39      0.689      0.558      0.578      0.326\n","                   bed        256        431      0.594      0.455      0.478      0.285      0.584      0.448      0.446       0.23\n","Speed: 0.2ms preprocess, 1.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n","Results saved to \u001b[1mruns/segment/custom_seg_model\u001b[0m\n"]},{"data":{"text/plain":["ultralytics.utils.metrics.SegmentMetrics object with attributes:\n","\n","ap_class_index: array([0, 1])\n","box: ultralytics.utils.metrics.Metric object\n","confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7b364f427310>\n","curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)', 'Precision-Recall(M)', 'F1-Confidence(M)', 'Precision-Confidence(M)', 'Recall-Confidence(M)']\n","curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,  0.00075627,  0.00037813,           0],\n","       [          1,           1,           1, ...,  0.00050032,  0.00025016,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.1318,      0.1318,     0.18669, ...,           0,           0,           0],\n","       [   0.076379,    0.076379,     0.12233, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.071735,    0.071735,     0.10589, ...,           1,           1,           1],\n","       [   0.040009,    0.040009,    0.066149, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.8101,      0.8101,     0.78788, ...,           0,           0,           0],\n","       [    0.83991,     0.83991,     0.81206, ...,           0,           0,           0]]), 'Confidence', 'Recall'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0005993,  0.00029965,           0],\n","       [          1,           1,           1, ...,  0.00029609,  0.00014804,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.12555,     0.12555,     0.17616, ...,           0,           0,           0],\n","       [   0.068784,    0.068784,      0.1108, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.068336,    0.068336,    0.099916, ...,           1,           1,           1],\n","       [    0.03603,     0.03603,    0.059912, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.77172,     0.77172,     0.74343, ...,           0,           0,           0],\n","       [    0.75638,     0.75638,      0.7355, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n","fitness: 0.6591090636850727\n","keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'metrics/precision(M)', 'metrics/recall(M)', 'metrics/mAP50(M)', 'metrics/mAP50-95(M)']\n","maps: array([    0.71537,     0.51504])\n","names: {0: 'person', 1: 'bed'}\n","plot: True\n","results_dict: {'metrics/precision(B)': 0.6530221461353476, 'metrics/recall(B)': 0.5152569781340083, 'metrics/mAP50(B)': 0.542060807825161, 'metrics/mAP50-95(B)': 0.3371852644156256, 'metrics/precision(M)': 0.6364842511026272, 'metrics/recall(M)': 0.5026857906208254, 'metrics/mAP50(M)': 0.5121921224473283, 'metrics/mAP50-95(M)': 0.2780189252041785, 'fitness': 0.6591090636850727}\n","save_dir: PosixPath('runs/segment/custom_seg_model')\n","seg: ultralytics.utils.metrics.Metric object\n","speed: {'preprocess': 0.20884256809949875, 'inference': 1.1142715811729431, 'loss': 0.0005038455128669739, 'postprocess': 1.4772219583392143}\n","task: 'segment'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from ultralytics import YOLO\n","\n","from albumentations import (\n","    Compose, Resize, RandomBrightnessContrast, HorizontalFlip,\n","    Rotate, GaussianBlur, CLAHE, HueSaturationValue\n",")\n","from torchvision.transforms import ToTensor  # PyTorch 전용\n","\n","\n","def get_transforms():\n","    return Compose([\n","        Resize(640, 640),  # 이미지 크기 조정\n","        RandomBrightnessContrast(p=0.3),  # 밝기/대비 조정\n","        HorizontalFlip(p=0.5),  # 수평 플립\n","        Rotate(limit=45, p=0.5),  # ±45도 회전\n","        GaussianNoise(p=0.3),  # 잡음 추가\n","        HueSaturationValue(p=0.3),  # 색조/채도 조정\n","        CLAHE(p=0.3),  # 대비 제한 히스토그램 평활화\n","        ToTensorV2()  # PyTorch 텐서로 변환\n","    ])\n","\n","# YOLOv8 Segmentation 모델 로드\n","model = YOLO('yolov8n-seg.pt')  # Segmentation 모델\n","pose_model = YOLO('yolov8n-pose.pt')\n","\n","# 모델 학습\n","model.train(\n","    data=yaml_path,           # 데이터셋 경로(YAML 파일)\n","    epochs=100,                # 학습 반복 횟수\n","    imgsz=640,                # 입력 이미지 크기\n","    batch=16,                  # 배치 크기\n","    name='custom_seg_model',  # 모델 저장 경로\n","    device=0                  # GPU 사용 (0번 GPU)\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":443,"status":"ok","timestamp":1733734151927,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"lQCsCl6pmzR8","outputId":"e4a74c6c-dbd7-4c90-9f67-fe85f235ba80"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model saved to: /content/drive/MyDrive/Seg_dataset\n"]}],"source":["import shutil\n","\n","# 모델 저장 경로\n","trained_model_path = '/content/runs/segment/custom_seg_model/weights/best.pt'\n","\n","# Google Drive 저장 경로\n","drive_save_path = '/content/drive/MyDrive/Seg_dataset'\n","\n","# 모델 파일 복사\n","shutil.copy(trained_model_path, drive_save_path)\n","\n","print(f\"Model saved to: {drive_save_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"lrW84cnZU1le"},"source":["## 테스트 및 후처리"]},{"cell_type":"markdown","metadata":{"id":"6AtFiC61jiiJ"},"source":["### keypoint와 mask 출력 및 keypoint 뼈대 연결"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1J4d7PsYLuIS1FbrQAcshnU9Lt8DyDtui"},"executionInfo":{"elapsed":23038,"status":"ok","timestamp":1733798107696,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"My6gOygHZW0A","outputId":"0aa0a5d6-9b0c-4891-8dce-93cfc7123915"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import numpy as np\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","from ultralytics import YOLO\n","\n","# YOLOv8 Segmentation 모델 로드\n","model = YOLO('/content/drive/MyDrive/Seg_dataset/best.pt')  # Segmentation 모델\n","pose_model = YOLO('yolov8n-pose.pt')\n","\n","\n","\n","# 중심점 계산 함수\n","def calculate_centroid(mask):\n","    indices = np.argwhere(mask)  # 마스크에서 1인 픽셀 좌표를 가져옴\n","    if indices.size == 0:\n","        return None  # 비어 있는 경우 None 반환\n","    return np.mean(indices, axis=0)  # 좌표 평균 계산\n","\n","# 위험 감지 함수\n","def detect_risk(pose_keypoints, bed_mask, image_shape, original_shape):\n","    if pose_keypoints is None or len(pose_keypoints) == 0 or len(pose_keypoints[0]) < 7:\n","        return \"Cannot assess risk. Missing or incomplete keypoints.\"\n","\n","    if bed_mask is None:\n","        return \"Cannot assess risk. Missing bed mask.\"\n","\n","    # 침대 가장자리 계산\n","    bed_mask_resized = cv2.resize(bed_mask, (image_shape[1], image_shape[0]))\n","    bed_edges = np.argwhere(bed_mask_resized > 0)\n","    if bed_edges.size == 0:\n","        return \"Cannot assess risk. Bed mask is empty.\"\n","\n","    bed_min_y, bed_max_y = np.min(bed_edges[:, 0]), np.max(bed_edges[:, 0])\n","    bed_min_x, bed_max_x = np.min(bed_edges[:, 1]), np.max(bed_edges[:, 1])\n","\n","    # 얼굴 Keypoints 확인 (코, 두 눈, 두 귀)\n","    face_keypoints = pose_keypoints[0][:5]  # 얼굴 Keypoints\n","    for idx, keypoint in enumerate(face_keypoints):\n","        x, y = keypoint[:2]\n","        x_original = x * (image_shape[1] / original_shape[1])\n","        y_original = y * (image_shape[0] / original_shape[0])\n","\n","        # 침대 내부 여부 확인\n","        if not (bed_min_x <= x_original <= bed_max_x and bed_min_y <= y_original <= bed_max_y):\n","            return f\"Warning: Baby's face keypoint {idx} is outside the bed!\"\n","\n","    # 코, 가슴, 배, 그리고 양 눈 Keypoints 추출\n","    nose, left_eye, right_eye = pose_keypoints[0][0], pose_keypoints[0][1], pose_keypoints[0][2]\n","    chest, stomach = pose_keypoints[0][5], pose_keypoints[0][6]\n","\n","    # 얼굴이 정면을 보고 있는지 확인\n","    eye_center_x = (left_eye[0] + right_eye[0]) / 2\n","    eye_center_y = (left_eye[1] + right_eye[1]) / 2\n","    if abs(nose[0] - eye_center_x) < image_shape[1] * 0.05 and abs(nose[1] - eye_center_y) < image_shape[0] * 0.05:\n","        return \"No risk detected. Baby's face is facing forward.\"\n","\n","    # 엎드린 자세 확인\n","    if chest[1] > nose[1] and stomach[1] > nose[1]:\n","        return \"Warning: Baby is lying face down!\"\n","\n","    # 코와 가슴 Keypoints 간 거리 계산\n","    vertical_distance = abs(nose[1] - chest[1])\n","    vertical_threshold = image_shape[0] * 0.1  # 이미지 높이의 10% 임계값\n","    if vertical_distance < vertical_threshold:\n","        return \"Warning: Baby's head is dangerously close to their chest!\"\n","\n","    return \"No risk detected.\"\n","\n","\n","# COCO Keypoint 연결 정의\n","pose_connections = [\n","    (0, 1), (0, 2), (1, 3), (2, 4),  # 머리 연결\n","    (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # 팔 연결\n","    (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # 다리 연결\n","]\n","\n","# 뼈대 시각화 함수\n","def draw_pose_skeleton(image, keypoints, connections, img_shape, orig_shape):\n","    for connection in connections:\n","        start_idx, end_idx = connection\n","        if start_idx >= len(keypoints) or end_idx >= len(keypoints):\n","            continue\n","\n","        # 시작점과 끝점 좌표 계산\n","        start_x, start_y, start_conf = keypoints[start_idx]\n","        end_x, end_y, end_conf = keypoints[end_idx]\n","        if start_conf < 0.5 or end_conf < 0.5:  # 신뢰도가 낮으면 생략\n","            continue\n","\n","        start_x = int(start_x * (img_shape[1] / orig_shape[1]))\n","        start_y = int(start_y * (img_shape[0] / orig_shape[0]))\n","        end_x = int(end_x * (img_shape[1] / orig_shape[1]))\n","        end_y = int(end_y * (img_shape[0] / orig_shape[0]))\n","\n","        # 유효한 키포인트만 연결\n","        if start_x > 0 and start_y > 0 and end_x > 0 and end_y > 0:\n","            cv2.line(image, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)  # 노란색 선\n","\n","    return image\n","\n","# 테스트 이미지 경로\n","test_images_dir = '/content/drive/MyDrive/Seg_dataset/Kakao'\n","image_paths = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith(('.jpg', '.png'))]\n","\n","\n","# 테스트 실행\n","for image_path in image_paths:\n","    # 이미지 로드\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Error: Unable to load image {image_path}\")\n","        continue\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # 모델 추론\n","    try:\n","        seg_results = model(image, conf=0.5, iou=0.4)  # IOU 임계값 설정\n","        pose_results = pose_model(image)  # Pose 추론\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        continue\n","\n","    # Segmentation Masks 및 Keypoints 추출\n","    masks = seg_results[0].masks.data.cpu().numpy() if seg_results[0].masks is not None else []\n","    pose_keypoints = pose_results[0].keypoints.data.cpu().numpy() if pose_results[0].keypoints is not None else None\n","\n","    # 침대 마스크 필터링\n","    bed_class_id = 1  # 침대 클래스 ID\n","    bed_mask = None\n","    if seg_results[0].boxes is not None:\n","        classes = seg_results[0].boxes.cls.cpu().numpy()\n","        bed_indices = np.where(classes == bed_class_id)[0]\n","        if len(bed_indices) > 0:\n","            bed_mask = masks[bed_indices[0]]\n","\n","    # Segmentation 마스크 시각화\n","    mask_overlay = np.zeros_like(image, dtype=np.uint8)\n","    if bed_mask is not None:\n","        bed_mask_resized = cv2.resize(bed_mask, (image.shape[1], image.shape[0]))\n","        mask_bool = bed_mask_resized > 0.5\n","        mask_overlay[mask_bool] = [255, 0, 0]  # 빨간색으로 표시\n","\n","        # 침대 가장자리 시각화\n","        bed_edges = np.argwhere(mask_bool)\n","        if bed_edges.size > 0:\n","            bed_min_y, bed_max_y = np.min(bed_edges[:, 0]), np.max(bed_edges[:, 0])\n","            bed_min_x, bed_max_x = np.min(bed_edges[:, 1]), np.max(bed_edges[:, 1])\n","            cv2.rectangle(mask_overlay, (bed_min_x, bed_min_y), (bed_max_x, bed_max_y), (255, 255, 0), 2)\n","\n","    # Keypoints 및 뼈대 시각화\n","    blended_image = cv2.addWeighted(image, 0.7, mask_overlay, 0.3, 0)\n","    if pose_keypoints is not None and len(pose_keypoints[0]) > 0:\n","        keypoints = pose_keypoints[0]  # 첫 번째 사람의 키포인트 사용\n","        # 뼈대 시각화\n","        blended_image = draw_pose_skeleton(blended_image, keypoints, pose_connections, image.shape, pose_results[0].orig_shape)\n","\n","        # 개별 키포인트 시각화\n","        for keypoint in keypoints:\n","            x, y, conf = keypoint\n","            if conf < 0.5:  # 신뢰도가 낮으면 생략\n","                continue\n","            x_original = int(x * (image.shape[1] / pose_results[0].orig_shape[1]))\n","            y_original = int(y * (image.shape[0] / pose_results[0].orig_shape[0]))\n","            cv2.circle(blended_image, (x_original, y_original), 5, (0, 255, 0), -1)  # 초록색 점\n","\n","    # 위험 감지\n","    risk_message = detect_risk(pose_keypoints, bed_mask, image.shape, pose_results[0].orig_shape)\n","\n","    # 결과 시각화\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(blended_image)\n","    plt.title(f\"{os.path.basename(image_path)} - {risk_message}\")\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","    # 이미지 파일 이름 및 상태 출력\n","    print(f\"Processed Image: {os.path.basename(image_path)}\")\n","    print(risk_message)\n"]},{"cell_type":"markdown","metadata":{"id":"odYF1AYFjoGo"},"source":["### 위험단계 표시(1단계: 가장자리로 이동, 2단계: 주요 kp 침대 테투리에서 벗어나는 경우)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1fqOuk6xC4gwoHEWSG3BB6KPKrA-qGmwa"},"executionInfo":{"elapsed":18129,"status":"ok","timestamp":1733798899996,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"Xjjx-VbudpuZ","outputId":"5eef70b3-b9af-4706-bb4e-646ea2932d09"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import numpy as np\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","from ultralytics import YOLO\n","\n","# YOLOv8 Segmentation 모델 로드\n","model = YOLO('/content/drive/MyDrive/Seg_dataset/best.pt')  # Segmentation 모델\n","pose_model = YOLO('yolov8n-pose.pt')\n","\n","# 중심점 계산 함수\n","def calculate_centroid(mask):\n","    indices = np.argwhere(mask)  # 마스크에서 1인 픽셀 좌표를 가져옴\n","    if indices.size == 0:\n","        return None  # 비어 있는 경우 None 반환\n","    return np.mean(indices, axis=0)  # 좌표 평균 계산\n","\n","# 위험 감지 함수 (위험 단계 1, 2 추가)\n","def detect_risk(pose_keypoints, bed_mask, image_shape, original_shape):\n","    if pose_keypoints is None or len(pose_keypoints) == 0 or len(pose_keypoints[0]) < 7:\n","        return \"Cannot assess risk. Missing or incomplete keypoints.\"\n","\n","    if bed_mask is None:\n","        return \"Cannot assess risk. Missing bed mask.\"\n","\n","    # 침대 가장자리 계산\n","    bed_mask_resized = cv2.resize(bed_mask, (image_shape[1], image_shape[0]))\n","    bed_edges = np.argwhere(bed_mask_resized > 0)\n","    if bed_edges.size == 0:\n","        return \"Cannot assess risk. Bed mask is empty.\"\n","\n","    bed_min_y, bed_max_y = np.min(bed_edges[:, 0]), np.max(bed_edges[:, 0])\n","    bed_min_x, bed_max_x = np.min(bed_edges[:, 1]), np.max(bed_edges[:, 1])\n","\n","    # 위험 단계 1: 침대 가장자리 접근\n","    danger_level_1 = False\n","    edge_threshold = 10  # 침대 가장자리로 간주할 임계값 (10픽셀)\n","\n","    # 위험 단계 2: 머리/손발이 침대 경계 밖으로 나감\n","    danger_level_2 = False\n","    keypoints_to_check = [0, 9, 10, 15, 16]  # 머리(0), 손목(9, 10), 발목(15, 16)\n","\n","    for idx, keypoint in enumerate(pose_keypoints[0]):\n","        x, y, conf = keypoint\n","        if conf < 0.5:  # 신뢰도 낮은 Keypoints는 생략\n","            continue\n","        x_original = x * (image_shape[1] / original_shape[1])\n","        y_original = y * (image_shape[0] / original_shape[0])\n","\n","        # 경계 밖 여부 확인\n","        if not (bed_min_x <= x_original <= bed_max_x and bed_min_y <= y_original <= bed_max_y):\n","            if idx in keypoints_to_check:  # 머리/손발이 경계 밖으로 나감\n","                danger_level_2 = True\n","                return f\"Warning Level 2: Keypoint {idx} is outside the bed!\"\n","        else:\n","            # 침대 가장자리로 접근 여부 확인\n","            if (\n","                (bed_min_x + edge_threshold <= x_original <= bed_max_x - edge_threshold)\n","                and (bed_min_y + edge_threshold <= y_original <= bed_max_y - edge_threshold)\n","            ):\n","                continue\n","            else:\n","                danger_level_1 = True\n","\n","    # 위험 단계 결과 반환\n","    if danger_level_2:\n","        return \"Warning Level 2: Baby is at high risk!\"\n","    if danger_level_1:\n","        return \"Warning Level 1: Baby is near the edge of the bed!\"\n","\n","    return \"No risk detected. Baby is safe.\"\n","\n","# COCO Keypoint 연결 정의\n","pose_connections = [\n","    (0, 1), (0, 2), (1, 3), (2, 4),  # 머리 연결\n","    (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # 팔 연결\n","    (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # 다리 연결\n","]\n","\n","# 뼈대 시각화 함수\n","def draw_pose_skeleton(image, keypoints, connections, img_shape, orig_shape):\n","    for connection in connections:\n","        start_idx, end_idx = connection\n","        if start_idx >= len(keypoints) or end_idx >= len(keypoints):\n","            continue\n","\n","        # 시작점과 끝점 좌표 계산\n","        start_x, start_y, start_conf = keypoints[start_idx]\n","        end_x, end_y, end_conf = keypoints[end_idx]\n","        if start_conf < 0.5 or end_conf < 0.5:  # 신뢰도가 낮으면 생략\n","            continue\n","\n","        start_x = int(start_x * (img_shape[1] / orig_shape[1]))\n","        start_y = int(start_y * (img_shape[0] / orig_shape[0]))\n","        end_x = int(end_x * (img_shape[1] / orig_shape[1]))\n","        end_y = int(end_y * (img_shape[0] / orig_shape[0]))\n","\n","        # 유효한 Keypoint만 연결\n","        if start_x > 0 and start_y > 0 and end_x > 0 and end_y > 0:\n","            cv2.line(image, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)  # 노란색 선\n","\n","    return image\n","\n","# 테스트 이미지 경로\n","test_images_dir = '/content/drive/MyDrive/Seg_dataset/Kakao'\n","image_paths = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith(('.jpg', '.png'))]\n","\n","# 테스트 실행\n","for image_path in image_paths:\n","    # 이미지 로드\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Error: Unable to load image {image_path}\")\n","        continue\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # 모델 추론\n","    try:\n","        seg_results = model(image, conf=0.5, iou=0.4)  # IOU 임계값 설정\n","        pose_results = pose_model(image)  # Pose 추론\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        continue\n","\n","    # Segmentation Masks 및 Keypoints 추출\n","    masks = seg_results[0].masks.data.cpu().numpy() if seg_results[0].masks is not None else []\n","    pose_keypoints = pose_results[0].keypoints.data.cpu().numpy() if pose_results[0].keypoints is not None else None\n","\n","    # 침대 마스크 필터링\n","    bed_class_id = 1  # 침대 클래스 ID\n","    bed_mask = None\n","    if seg_results[0].boxes is not None:\n","        classes = seg_results[0].boxes.cls.cpu().numpy()\n","        bed_indices = np.where(classes == bed_class_id)[0]\n","        if len(bed_indices) > 0:\n","            bed_mask = masks[bed_indices[0]]\n","\n","    # Segmentation 마스크 시각화\n","    mask_overlay = np.zeros_like(image, dtype=np.uint8)\n","    if bed_mask is not None:\n","        bed_mask_resized = cv2.resize(bed_mask, (image.shape[1], image.shape[0]))\n","        mask_bool = bed_mask_resized > 0.5\n","        mask_overlay[mask_bool] = [255, 0, 0]  # 빨간색으로 표시\n","\n","        # 침대 가장자리 시각화\n","        bed_edges = np.argwhere(mask_bool)\n","        if bed_edges.size > 0:\n","            bed_min_y, bed_max_y = np.min(bed_edges[:, 0]), np.max(bed_edges[:, 0])\n","            bed_min_x, bed_max_x = np.min(bed_edges[:, 1]), np.max(bed_edges[:, 1])\n","            cv2.rectangle(mask_overlay, (bed_min_x, bed_min_y), (bed_max_x, bed_max_y), (255, 255, 0), 2)\n","\n","    # Keypoints 및 뼈대 시각화\n","    blended_image = cv2.addWeighted(image, 0.7, mask_overlay, 0.3, 0)\n","    if pose_keypoints is not None and len(pose_keypoints[0]) > 0:\n","        keypoints = pose_keypoints[0]  # 첫 번째 사람의 Keypoint 사용\n","        # 뼈대 시각화\n","        blended_image = draw_pose_skeleton(blended_image, keypoints, pose_connections, image.shape, pose_results[0].orig_shape)\n","\n","        # 개별 Keypoint 시각화\n","        for keypoint in keypoints:\n","            x, y, conf = keypoint\n","            if conf < 0.5:  # 신뢰도가 낮으면 생략\n","                continue\n","            x_original = int(x * (image.shape[1] / pose_results[0].orig_shape[1]))\n","            y_original = int(y * (image.shape[0] / pose_results[0].orig_shape[0]))\n","            cv2.circle(blended_image, (x_original, y_original), 5, (0, 255, 0), -1)  # 초록색 점\n","\n","    # 위험 감지\n","    risk_message = detect_risk(pose_keypoints, bed_mask, image.shape, pose_results[0].orig_shape)\n","\n","    # 결과 시각화\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(blended_image)\n","    plt.title(f\"{os.path.basename(image_path)} - {risk_message}\")\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","    # 이미지 파일 이름 및 상태 출력\n","    print(f\"Processed Image: {os.path.basename(image_path)}\")\n","    print(risk_message)\n"]},{"cell_type":"markdown","metadata":{"id":"HnT_les_6dRe"},"source":[]},{"cell_type":"markdown","metadata":{"id":"Ui7YhTINkELy"},"source":["### 침대 객체를 인식 못하거나 사람보다 작은 크기로 인식하면, person을 제외한 나머지 부분을 침대로 인식"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1t8MdTpe5PbY5x8ud6mfMfP4WRq1OmjfV"},"executionInfo":{"elapsed":76693,"status":"ok","timestamp":1733799728830,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"9srfdwSOe6pH","outputId":"cfb2118c-99c5-45ee-a8bd-37588a3af2ac"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import numpy as np\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","from ultralytics import YOLO\n","\n","# YOLOv8 Segmentation 모델 로드\n","model = YOLO('/content/drive/MyDrive/Seg_dataset/best.pt')  # Segmentation 모델\n","pose_model = YOLO('yolov8n-pose.pt')\n","\n","# 테스트 이미지 경로\n","test_images_dir = '/content/drive/MyDrive/baby_Prone'\n","image_paths = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith(('.jpg', '.png'))]\n","\n","\n","# 중심점 계산 함수\n","def calculate_centroid(mask):\n","    indices = np.argwhere(mask)  # 마스크에서 1인 픽셀 좌표를 가져옴\n","    if indices.size == 0:\n","        return None  # 비어 있는 경우 None 반환\n","    return np.mean(indices, axis=0)  # 좌표 평균 계산\n","\n","# 침대 마스크 보정 함수\n","def refine_bed_mask(image_shape, bed_mask, person_mask):\n","    \"\"\"\n","    침대 마스크가 없거나 작을 경우 person 마스크를 제외한 나머지를 침대 마스크로 인식.\n","    \"\"\"\n","    if bed_mask is None or np.sum(bed_mask) < 0.1 * (image_shape[0] * image_shape[1]):  # 10% 이하인 경우\n","        print(\"Refining bed mask using person mask...\")\n","        bed_mask = np.ones(image_shape[:2], dtype=np.uint8)  # 전체 영역을 1로 초기화\n","        if person_mask is not None:\n","            person_mask_resized = cv2.resize(person_mask, (image_shape[1], image_shape[0]))\n","            bed_mask[person_mask_resized > 0.5] = 0  # person 영역 제외\n","    return bed_mask\n","\n","# 위험 감지 함수 (위험 단계 1, 2 추가)\n","def detect_risk(pose_keypoints, bed_mask, image_shape, original_shape):\n","    if pose_keypoints is None or len(pose_keypoints) == 0 or len(pose_keypoints[0]) < 7:\n","        return \"Cannot assess risk. Missing or incomplete keypoints.\"\n","\n","    if bed_mask is None:\n","        return \"Cannot assess risk. Missing bed mask.\"\n","\n","    # 침대 가장자리 계산\n","    bed_mask_resized = cv2.resize(bed_mask, (image_shape[1], image_shape[0]))\n","    bed_edges = np.argwhere(bed_mask_resized > 0)\n","    if bed_edges.size == 0:\n","        return \"Cannot assess risk. Bed mask is empty.\"\n","\n","    bed_min_y, bed_max_y = np.min(bed_edges[:, 0]), np.max(bed_edges[:, 0])\n","    bed_min_x, bed_max_x = np.min(bed_edges[:, 1]), np.max(bed_edges[:, 1])\n","\n","    # 위험 단계 1: 침대 가장자리 접근\n","    danger_level_1 = False\n","    edge_threshold = 10  # 침대 가장자리로 간주할 임계값 (10픽셀)\n","\n","    # 위험 단계 2: 머리/손발이 침대 경계 밖으로 나감\n","    danger_level_2 = False\n","    keypoints_to_check = [0, 9, 10, 15, 16]  # 머리(0), 손목(9, 10), 발목(15, 16)\n","\n","    for idx, keypoint in enumerate(pose_keypoints[0]):\n","        x, y, conf = keypoint\n","        if conf < 0.5:  # 신뢰도 낮은 Keypoints는 생략\n","            continue\n","        x_original = x * (image_shape[1] / original_shape[1])\n","        y_original = y * (image_shape[0] / original_shape[0])\n","\n","        # 경계 밖 여부 확인\n","        if not (bed_min_x <= x_original <= bed_max_x and bed_min_y <= y_original <= bed_max_y):\n","            if idx in keypoints_to_check:  # 머리/손발이 경계 밖으로 나감\n","                danger_level_2 = True\n","                return f\"Warning Level 2: Keypoint {idx} is outside the bed!\"\n","        else:\n","            # 침대 가장자리로 접근 여부 확인\n","            if (\n","                (bed_min_x + edge_threshold <= x_original <= bed_max_x - edge_threshold)\n","                and (bed_min_y + edge_threshold <= y_original <= bed_max_y - edge_threshold)\n","            ):\n","                continue\n","            else:\n","                danger_level_1 = True\n","\n","    # 위험 단계 결과 반환\n","    if danger_level_2:\n","        return \"Warning Level 2: Baby is at high risk!\"\n","    if danger_level_1:\n","        return \"Warning Level 1: Baby is near the edge of the bed!\"\n","\n","    return \"No risk detected. Baby is safe.\"\n","\n","# COCO Keypoint 연결 정의\n","pose_connections = [\n","    (0, 1), (0, 2), (1, 3), (2, 4),  # 머리 연결\n","    (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # 팔 연결\n","    (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # 다리 연결\n","]\n","\n","# 뼈대 시각화 함수\n","def draw_pose_skeleton(image, keypoints, connections, img_shape, orig_shape):\n","    for connection in connections:\n","        start_idx, end_idx = connection\n","        if start_idx >= len(keypoints) or end_idx >= len(keypoints):\n","            continue\n","\n","        # 시작점과 끝점 좌표 계산\n","        start_x, start_y, start_conf = keypoints[start_idx]\n","        end_x, end_y, end_conf = keypoints[end_idx]\n","        if start_conf < 0.5 or end_conf < 0.5:  # 신뢰도가 낮으면 생략\n","            continue\n","\n","        start_x = int(start_x * (img_shape[1] / orig_shape[1]))\n","        start_y = int(start_y * (img_shape[0] / orig_shape[0]))\n","        end_x = int(end_x * (img_shape[1] / orig_shape[1]))\n","        end_y = int(end_y * (img_shape[0] / orig_shape[0]))\n","\n","        # 유효한 Keypoint만 연결\n","        if start_x > 0 and start_y > 0 and end_x > 0 and end_y > 0:\n","            cv2.line(image, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)  # 노란색 선\n","\n","    return image\n","\n","\n","# 테스트 실행\n","for image_path in image_paths:\n","    # 이미지 로드\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Error: Unable to load image {image_path}\")\n","        continue\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # 모델 추론\n","    try:\n","        seg_results = model(image, conf=0.5, iou=0.4)  # IOU 임계값 설정\n","        pose_results = pose_model(image)  # Pose 추론\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        continue\n","\n","    # Segmentation Masks 및 Keypoints 추출\n","    masks = seg_results[0].masks.data.cpu().numpy() if seg_results[0].masks is not None else []\n","    pose_keypoints = pose_results[0].keypoints.data.cpu().numpy() if pose_results[0].keypoints is not None else None\n","\n","    # 침대 및 사람 마스크 필터링\n","    bed_class_id = 1  # 침대 클래스 ID\n","    person_class_id = 0  # 사람 클래스 ID\n","    bed_mask = None\n","    person_mask = None\n","\n","    if seg_results[0].boxes is not None:\n","        classes = seg_results[0].boxes.cls.cpu().numpy()\n","        for i, cls in enumerate(classes):\n","            if cls == bed_class_id:\n","                bed_mask = masks[i]\n","            elif cls == person_class_id:\n","                person_mask = masks[i]\n","\n","    # 침대 마스크 보정\n","    bed_mask = refine_bed_mask(image.shape, bed_mask, person_mask)\n","\n","    # Segmentation 마스크 시각화\n","    mask_overlay = np.zeros_like(image, dtype=np.uint8)\n","    if bed_mask is not None:\n","        bed_mask_resized = cv2.resize(bed_mask, (image.shape[1], image.shape[0]))\n","        mask_bool = bed_mask_resized > 0.5\n","        mask_overlay[mask_bool] = [255, 0, 0]  # 빨간색으로 표시\n","\n","        # 침대 가장자리 시각화\n","        bed_edges = np.argwhere(mask_bool)\n","        if bed_edges.size > 0:\n","            bed_min_y, bed_max_y = np.min(bed_edges[:, 0]), np.max(bed_edges[:, 0])\n","            bed_min_x, bed_max_x = np.min(bed_edges[:, 1]), np.max(bed_edges[:, 1])\n","            cv2.rectangle(mask_overlay, (bed_min_x, bed_min_y), (bed_max_x, bed_max_y), (255, 255, 0), 2)\n","\n","    # Keypoints 및 뼈대 시각화\n","    blended_image = cv2.addWeighted(image, 0.7, mask_overlay, 0.3, 0)\n","    if pose_keypoints is not None and len(pose_keypoints[0]) > 0:\n","        keypoints = pose_keypoints[0]  # 첫 번째 사람의 Keypoint 사용\n","        # 뼈대 시각화\n","        blended_image = draw_pose_skeleton(blended_image, keypoints, pose_connections, image.shape, pose_results[0].orig_shape)\n","\n","        # 개별 Keypoint 시각화\n","        for keypoint in keypoints:\n","            x, y, conf = keypoint\n","            if conf < 0.5:  # 신뢰도가 낮으면 생략\n","                continue\n","            x_original = int(x * (image.shape[1] / pose_results[0].orig_shape[1]))\n","            y_original = int(y * (image.shape[0] / pose_results[0].orig_shape[0]))\n","            cv2.circle(blended_image, (x_original, y_original), 5, (0, 255, 0), -1)  # 초록색 점\n","\n","    # 위험 감지\n","    risk_message = detect_risk(pose_keypoints, bed_mask, image.shape, pose_results[0].orig_shape)\n","\n","    # 결과 시각화\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(blended_image)\n","    plt.title(f\"{os.path.basename(image_path)} - {risk_message}\")\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","    # 이미지 파일 이름 및 상태 출력\n","    print(f\"Processed Image: {os.path.basename(image_path)}\")\n","    print(risk_message)\n"]},{"cell_type":"markdown","metadata":{"id":"4K4s7B7kkh5B"},"source":["### 뒤집기 자세 추가(윤곽선 분석 및 눈코입kp이용)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1PITcaof3DNlSSzKFfxPpu4JNesnWAhcT"},"executionInfo":{"elapsed":77026,"status":"ok","timestamp":1733801340504,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"JC1bYNTCh3I1","outputId":"fd7b487b-22cd-44f5-e555-57635cff756c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import numpy as np\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","from ultralytics import YOLO\n","\n","# YOLOv8 Segmentation 모델 로드\n","model = YOLO('/content/drive/MyDrive/Seg_dataset/best.pt')  # Segmentation 모델\n","pose_model = YOLO('yolov8n-pose.pt')\n","\n","# 테스트 이미지 경로\n","test_images_dir = '/content/drive/MyDrive/baby_Prone'\n","image_paths = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith(('.jpg', '.png'))]\n","\n","# 중심점 계산 함수\n","def calculate_centroid(mask):\n","    indices = np.argwhere(mask)  # 마스크에서 1인 픽셀 좌표를 가져옴\n","    if indices.size == 0:\n","        return None  # 비어 있는 경우 None 반환\n","    return np.mean(indices, axis=0)  # 좌표 평균 계산\n","\n","# 침대 마스크 보정 함수\n","def refine_bed_mask(image_shape, bed_mask, person_mask):\n","    \"\"\"\n","    침대 마스크가 없거나 작을 경우 person 마스크를 제외한 나머지를 침대 마스크로 인식.\n","    \"\"\"\n","    if bed_mask is None or np.sum(bed_mask) < 0.1 * (image_shape[0] * image_shape[1]):  # 10% 이하인 경우\n","        print(\"Refining bed mask using person mask...\")\n","        bed_mask = np.ones(image_shape[:2], dtype=np.uint8)  # 전체 영역을 1로 초기화\n","        if person_mask is not None:\n","            person_mask_resized = cv2.resize(person_mask, (image_shape[1], image_shape[0]))\n","            bed_mask[person_mask_resized > 0.5] = 0  # person 영역 제외\n","    return bed_mask\n","\n","# 윤곽선 분석 기반 뒤집기 자세 감지\n","def detect_prone_via_contour(person_mask):\n","    \"\"\"\n","    윤곽선 분석을 통해 둥근 형태(뒷통수)를 판별하여 뒤집기 자세 탐지.\n","    \"\"\"\n","    if person_mask is None:\n","        return False, \"No person mask available for contour analysis.\"\n","\n","    contours, _ = cv2.findContours((person_mask > 0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    if len(contours) > 0:\n","        contour = max(contours, key=cv2.contourArea)\n","        convexity = cv2.isContourConvex(contour)  # 윤곽선이 둥근지 확인\n","        if convexity:\n","            return True, \"Warning: Head contour detected as round (prone position).\"\n","    return False, \"Head contour not round (no prone detected).\"\n","\n","# 키포인트 기반 뒤집기 자세 감지\n","def detect_prone_via_keypoints(pose_keypoints):\n","    \"\"\"\n","    얼굴 Keypoints(눈, 코)가 모두 없는 경우 뒤집기 자세로 간주.\n","    \"\"\"\n","    if pose_keypoints is None or len(pose_keypoints) == 0:\n","        return False, \"Pose keypoints missing or incomplete.\"\n","\n","    # 얼굴 Keypoints 확인\n","    try:\n","        nose = pose_keypoints[0][0]  # 코\n","        left_eye = pose_keypoints[0][1]  # 왼쪽 눈\n","        right_eye = pose_keypoints[0][2]  # 오른쪽 눈\n","    except IndexError:\n","        return False, \"Keypoints array does not contain sufficient data.\"\n","\n","    # Keypoints의 신뢰도 확인\n","    if nose[2] < 0.5 and left_eye[2] < 0.5 and right_eye[2] < 0.5:\n","        return True, \"Warning: Face keypoints missing (prone position detected)!\"\n","\n","    return False, \"No prone position detected via keypoints.\"\n","\n","\n","# COCO Keypoint 연결 정의\n","pose_connections = [\n","    (0, 1), (0, 2), (1, 3), (2, 4),  # 머리 연결\n","    (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # 팔 연결\n","    (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # 다리 연결\n","]\n","\n","# 뼈대 시각화 함수\n","def draw_pose_skeleton(image, keypoints, connections, img_shape, orig_shape):\n","    for connection in connections:\n","        start_idx, end_idx = connection\n","        if start_idx >= len(keypoints) or end_idx >= len(keypoints):\n","            continue\n","\n","        # 시작점과 끝점 좌표 계산\n","        start_x, start_y, start_conf = keypoints[start_idx]\n","        end_x, end_y, end_conf = keypoints[end_idx]\n","        if start_conf < 0.5 or end_conf < 0.5:  # 신뢰도가 낮으면 생략\n","            continue\n","\n","        start_x = int(start_x * (img_shape[1] / orig_shape[1]))\n","        start_y = int(start_y * (img_shape[0] / orig_shape[0]))\n","        end_x = int(end_x * (img_shape[1] / orig_shape[1]))\n","        end_y = int(end_y * (img_shape[0] / orig_shape[0]))\n","\n","        # 유효한 Keypoint만 연결\n","        if start_x > 0 and start_y > 0 and end_x > 0 and end_y > 0:\n","            cv2.line(image, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)  # 노란색 선\n","\n","    return image\n","\n","\n","# 테스트 실행\n","for image_path in image_paths:\n","    # 이미지 로드\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Error: Unable to load image {image_path}\")\n","        continue\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # 모델 추론\n","    try:\n","        seg_results = model(image, conf=0.5, iou=0.4)  # IOU 임계값 설정\n","        pose_results = pose_model(image)  # Pose 추론\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        continue\n","\n","    # Segmentation Masks 및 Keypoints 추출\n","    masks = seg_results[0].masks.data.cpu().numpy() if seg_results[0].masks is not None else []\n","    pose_keypoints = pose_results[0].keypoints.data.cpu().numpy() if pose_results[0].keypoints is not None else None\n","\n","    # 침대 및 사람 마스크 필터링\n","    bed_class_id = 1  # 침대 클래스 ID\n","    person_class_id = 0  # 사람 클래스 ID\n","    bed_mask = None\n","    person_mask = None\n","\n","    if seg_results[0].boxes is not None:\n","        classes = seg_results[0].boxes.cls.cpu().numpy()\n","        for i, cls in enumerate(classes):\n","            if cls == bed_class_id:\n","                bed_mask = masks[i]\n","            elif cls == person_class_id:\n","                person_mask = masks[i]\n","\n","    # 침대 마스크 보정\n","    bed_mask = refine_bed_mask(image.shape, bed_mask, person_mask)\n","\n","    # Segmentation 마스크 시각화\n","    mask_overlay = np.zeros_like(image, dtype=np.uint8)\n","    if bed_mask is not None:\n","        bed_mask_resized = cv2.resize(bed_mask, (image.shape[1], image.shape[0]))\n","        mask_bool = bed_mask_resized > 0.5\n","        mask_overlay[mask_bool] = [255, 0, 0]  # 빨간색으로 표시\n","\n","        # 침대 가장자리 시각화\n","        bed_edges = np.argwhere(mask_bool)\n","        if bed_edges.size > 0:\n","            bed_min_y, bed_max_y = np.min(bed_edges[:, 0]), np.max(bed_edges[:, 0])\n","            bed_min_x, bed_max_x = np.min(bed_edges[:, 1]), np.max(bed_edges[:, 1])\n","            cv2.rectangle(mask_overlay, (bed_min_x, bed_min_y), (bed_max_x, bed_max_y), (255, 255, 0), 2)\n","\n","    # Keypoints 및 뼈대 시각화\n","    blended_image = cv2.addWeighted(image, 0.7, mask_overlay, 0.3, 0)\n","    if pose_keypoints is not None and len(pose_keypoints[0]) > 0:\n","        keypoints = pose_keypoints[0]  # 첫 번째 사람의 Keypoint 사용\n","        # 뼈대 시각화\n","        blended_image = draw_pose_skeleton(blended_image, keypoints, pose_connections, image.shape, pose_results[0].orig_shape)\n","\n","        # 개별 Keypoint 시각화\n","        for keypoint in keypoints:\n","            x, y, conf = keypoint\n","            if conf < 0.5:  # 신뢰도가 낮으면 생략\n","                continue\n","            x_original = int(x * (image.shape[1] / pose_results[0].orig_shape[1]))\n","            y_original = int(y * (image.shape[0] / pose_results[0].orig_shape[0]))\n","            cv2.circle(blended_image, (x_original, y_original), 5, (0, 255, 0), -1)  # 초록색 점\n","\n","    # 위험 감지\n","    risk_message = detect_risk(pose_keypoints, bed_mask, image.shape, pose_results[0].orig_shape)\n","\n","    # 뒤집기 자세 감지\n","    prone_contour_detected, contour_message = detect_prone_via_contour(person_mask)\n","    prone_keypoints_detected, keypoints_message = detect_prone_via_keypoints(pose_keypoints)\n","\n","    # 뒤집기 자세 메시지 선택\n","    if prone_contour_detected:\n","        prone_message = contour_message\n","    elif prone_keypoints_detected:\n","        prone_message = keypoints_message\n","    else:\n","        prone_message = \"No prone position detected.\"\n","\n","    # 결과 시각화\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(blended_image)\n","    plt.title(f\"{os.path.basename(image_path)} - {risk_message} - {prone_message}\")\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","    # 이미지 파일 이름 및 상태 출력\n","    print(f\"Processed Image: {os.path.basename(image_path)}\")\n","    print(risk_message)\n","    print(prone_message)\n"]},{"cell_type":"markdown","metadata":{"id":"RlmP8Ozhp37d"},"source":["## 일정시간 움직임 감지 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2648,"status":"ok","timestamp":1734068979118,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"VKwMi9HuqJ50","outputId":"6b7683d2-f2dd-43ae-f577-f00ef3071939"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2024.12.6)\n"]}],"source":["!pip install yt-dlp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3092,"status":"ok","timestamp":1734065121953,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"sju4hf9bqXaF","outputId":"d22bd4b9-f091-45fd-f322-b3dfd6943898","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.49)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.13)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6772,"status":"ok","timestamp":1734070125201,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"7QD3qmI5qJ_U","outputId":"e5889d72-9645-430c-9cd4-bd1a203a144c","collapsed":true},"outputs":[{"output_type":"stream","name":"stderr","text":["[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n","[debug] yt-dlp version stable@2024.12.06 from yt-dlp/yt-dlp [4bd265539] (pip) API\n","[debug] params: {'format': 'bestvideo+bestaudio/best', 'outtmpl': 'test_video_1.mp4', 'merge_output_format': 'mp4', 'verbose': True, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.15 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}}\n","[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n","[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n","[debug] Optional libraries: certifi-2024.08.30, requests-2.32.3, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.2.3\n","[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n","[debug] Request Handlers: urllib, requests\n","[debug] Loaded 1837 extractors\n"]},{"output_type":"stream","name":"stdout","text":["[youtube] Extracting URL: https://www.youtube.com/watch?v=yyxul1GjHmw\n","[youtube] yyxul1GjHmw: Downloading webpage\n","[youtube] yyxul1GjHmw: Downloading ios player API JSON\n","[youtube] yyxul1GjHmw: Downloading mweb player API JSON\n"]},{"output_type":"stream","name":"stderr","text":["[debug] Loading youtube-nsig.f8f53e1a from cache\n","[debug] [youtube] Decrypted nsig LdfD4InI3ExoU59qOPL => aFzN2e-qaebQhQ\n","[debug] Loading youtube-nsig.f8f53e1a from cache\n","[debug] [youtube] Decrypted nsig 71RssNsHB_qDlspUuDk => K-yo7iuDEqKAhQ\n"]},{"output_type":"stream","name":"stdout","text":["[youtube] yyxul1GjHmw: Downloading m3u8 information\n"]},{"output_type":"stream","name":"stderr","text":["[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec, channels, acodec, lang, proto\n","[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec, channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"]},{"output_type":"stream","name":"stdout","text":["[info] yyxul1GjHmw: Downloading 1 format(s): 247+251\n","[download] test_video_1.mp4 has already been downloaded\n"]},{"output_type":"stream","name":"stderr","text":["[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n","[debug] yt-dlp version stable@2024.12.06 from yt-dlp/yt-dlp [4bd265539] (pip) API\n","[debug] params: {'format': 'bestvideo+bestaudio/best', 'outtmpl': 'test_video_2.mp4', 'merge_output_format': 'mp4', 'verbose': True, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.15 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}}\n","[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n","[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n","[debug] Optional libraries: certifi-2024.08.30, requests-2.32.3, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.2.3\n","[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n","[debug] Request Handlers: urllib, requests\n","[debug] Loaded 1837 extractors\n"]},{"output_type":"stream","name":"stdout","text":["Video downloaded successfully!\n","[youtube] Extracting URL: https://www.youtube.com/watch?v=liYaasCvbwI\n","[youtube] liYaasCvbwI: Downloading webpage\n","[youtube] liYaasCvbwI: Downloading ios player API JSON\n","[youtube] liYaasCvbwI: Downloading mweb player API JSON\n"]},{"output_type":"stream","name":"stderr","text":["[debug] Loading youtube-nsig.f8f53e1a from cache\n","[debug] [youtube] Decrypted nsig i01yiReDGB8d699MvOO => xQuC_xiGc7MNIw\n","[debug] Loading youtube-nsig.f8f53e1a from cache\n","[debug] [youtube] Decrypted nsig fZTyHvpUFu2LDmrpaHB => uK_wdZoa5mNynw\n"]},{"output_type":"stream","name":"stdout","text":["[youtube] liYaasCvbwI: Downloading m3u8 information\n"]},{"output_type":"stream","name":"stderr","text":["[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec, channels, acodec, lang, proto\n","[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec, channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"]},{"output_type":"stream","name":"stdout","text":["[info] liYaasCvbwI: Downloading 1 format(s): 137+251\n","[download] test_video_2.mp4 has already been downloaded\n"]},{"output_type":"stream","name":"stderr","text":["[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n","[debug] yt-dlp version stable@2024.12.06 from yt-dlp/yt-dlp [4bd265539] (pip) API\n","[debug] params: {'format': 'bestvideo+bestaudio/best', 'outtmpl': 'test_video_5.mp4', 'merge_output_format': 'mp4', 'verbose': True, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.15 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}}\n","[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n","[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n","[debug] Optional libraries: certifi-2024.08.30, requests-2.32.3, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.2.3\n","[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n","[debug] Request Handlers: urllib, requests\n","[debug] Loaded 1837 extractors\n"]},{"output_type":"stream","name":"stdout","text":["Video downloaded successfully!\n","[youtube] Extracting URL: https://www.youtube.com/watch?v=X_PgMoNZJIU\n","[youtube] X_PgMoNZJIU: Downloading webpage\n","[youtube] X_PgMoNZJIU: Downloading ios player API JSON\n","[youtube] X_PgMoNZJIU: Downloading mweb player API JSON\n"]},{"output_type":"stream","name":"stderr","text":["[debug] Loading youtube-nsig.f8f53e1a from cache\n","[debug] [youtube] Decrypted nsig cfI9NOEJGzL6R-B1MP0 => rf0f8ierlVcuJQ\n","[debug] Loading youtube-nsig.f8f53e1a from cache\n","[debug] [youtube] Decrypted nsig 47NhyvmT4bnLZE1m-q_ => H7-wdrm928ZYCw\n"]},{"output_type":"stream","name":"stdout","text":["[youtube] X_PgMoNZJIU: Downloading m3u8 information\n"]},{"output_type":"stream","name":"stderr","text":["[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec, channels, acodec, lang, proto\n","[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec, channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"]},{"output_type":"stream","name":"stdout","text":["[info] X_PgMoNZJIU: Downloading 1 format(s): 248+251\n"]},{"output_type":"stream","name":"stderr","text":["[debug] Invoking http downloader on \"https://rr2---sn-5uaezned.googlevideo.com/videoplayback?expire=1734091724&ei=bM9bZ4OTEJy2kucPgvKqeQ&ip=35.196.31.99&id=o-AJwNkoUFgvrmNeV9C6AXE48UvvRPeiQvqjouLHJK4481&itag=248&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1734070124%2C&mh=u7&mm=31%2C26&mn=sn-5uaezned%2Csn-a5mekn6z&ms=au%2Conr&mv=m&mvi=2&pl=22&rms=au%2Cau&initcwndbps=8560000&bui=AfMhrI_ceHFmjIs1tB5WyLqAbrY1eEcmIsQLqM0pN46EALFsOPvHQDQ8iP_qxORfQAx676nJHqAdN5LT&spc=x-caUO9myd5HimmbS9J3xw3YBK_Zk9qdaF7giFZuFBUfnmBwSw&vprv=1&svpuc=1&mime=video%2Fwebm&rqh=1&gir=yes&clen=3553884&dur=40.773&lmt=1710310554981002&mt=1734069678&fvip=4&keepalive=yes&fexp=51326932%2C51335594%2C51347747&c=IOS&txp=530F224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhANOqp0DZqbvfJzPDrtW8BU_VUyzwpWzNq6EfTvKWvamJAiAvoDfe_aUlKMjwIOjKNs15VYuN1MEzbgRXp9XnDYMJyg%3D%3D&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=AGluJ3MwRQIgER_IRQK8YM0NO5hSsZklIpSle2QDdkUkHLw2WOughSgCIQCtIZENYbohs0vctQgtEm5RAA1nAs1Vk1aOBLY83Xn_Vw%3D%3D\"\n"]},{"output_type":"stream","name":"stdout","text":["[download] Destination: test_video_5.f248.webm\n","[download] 100% of    3.39MiB in 00:00:00 at 21.23MiB/s  \n"]},{"output_type":"stream","name":"stderr","text":["[debug] Invoking http downloader on \"https://rr2---sn-5uaezned.googlevideo.com/videoplayback?expire=1734091724&ei=bM9bZ4OTEJy2kucPgvKqeQ&ip=35.196.31.99&id=o-AJwNkoUFgvrmNeV9C6AXE48UvvRPeiQvqjouLHJK4481&itag=251&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1734070124%2C&mh=u7&mm=31%2C26&mn=sn-5uaezned%2Csn-a5mekn6z&ms=au%2Conr&mv=m&mvi=2&pl=22&rms=au%2Cau&initcwndbps=8560000&bui=AfMhrI_ceHFmjIs1tB5WyLqAbrY1eEcmIsQLqM0pN46EALFsOPvHQDQ8iP_qxORfQAx676nJHqAdN5LT&spc=x-caUO9myd5HimmbS9J3xw3YBK_Zk9qdaF7giFZuFBUfnmBwSw&vprv=1&svpuc=1&mime=audio%2Fwebm&rqh=1&gir=yes&clen=418628&dur=40.801&lmt=1710310547824188&mt=1734069678&fvip=4&keepalive=yes&fexp=51326932%2C51335594%2C51347747&c=IOS&txp=5318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cspc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhAL59O35CsTxBzluX6jVwubOs_IP_C7FgmAP8bBJoJ8kuAiByXpTXgII0fAxp7l6HMuSfVzCYW-F_zWL1uQFmBy3OgA%3D%3D&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=AGluJ3MwRQIgER_IRQK8YM0NO5hSsZklIpSle2QDdkUkHLw2WOughSgCIQCtIZENYbohs0vctQgtEm5RAA1nAs1Vk1aOBLY83Xn_Vw%3D%3D\"\n"]},{"output_type":"stream","name":"stdout","text":["[download] Destination: test_video_5.f251.webm\n","[download] 100% of  408.82KiB in 00:00:00 at 8.27MiB/s   \n","[Merger] Merging formats into \"test_video_5.mp4\"\n"]},{"output_type":"stream","name":"stderr","text":["[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i file:test_video_5.f248.webm -i file:test_video_5.f251.webm -c copy -map 0:v:0 -map 1:a:0 -movflags +faststart file:test_video_5.temp.mp4\n"]},{"output_type":"stream","name":"stdout","text":["Deleting original file test_video_5.f251.webm (pass -k to keep)\n","Deleting original file test_video_5.f248.webm (pass -k to keep)\n","Video downloaded successfully!\n"]}],"source":["import yt_dlp\n","\n","def download_youtube_video(video_url, save_path):\n","    ydl_opts = {\n","        'format': 'bestvideo+bestaudio/best',\n","        'outtmpl': save_path,\n","        'merge_output_format': 'mp4',\n","        'verbose': True\n","    }\n","    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n","        ydl.download([video_url])\n","\n","# 다운로드 실행\n","video_url_1 = \"https://www.youtube.com/watch?v=yyxul1GjHmw\"\n","download_youtube_video(video_url_1, \"test_video_1.mp4\")\n","print(\"Video downloaded successfully!\")\n","\n","video_url_2=\"https://www.youtube.com/watch?v=liYaasCvbwI\"\n","download_youtube_video(video_url_2, \"test_video_2.mp4\")\n","print(\"Video downloaded successfully!\")\n","\n","video_url_5=\"https://www.youtube.com/watch?v=X_PgMoNZJIU\"\n","download_youtube_video(video_url_5, \"test_video_5.mp4\")\n","print(\"Video downloaded successfully!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9703,"status":"ok","timestamp":1734070166670,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"VRvHJVqxqQ_0","outputId":"d14b71d6-8d52-4732-89f0-ee6f9aee5f9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Frames saved to test_frames_1\n","Frames saved to test_frames_2\n","Frames saved to test_frames_5\n"]}],"source":["import cv2\n","import os\n","\n","# 영상에서 프레임 추출 함수\n","def extract_frames(video_path, output_folder=\"frames\", frame_interval=5):\n","    os.makedirs(output_folder, exist_ok=True)\n","    cap = cv2.VideoCapture(video_path)\n","    frame_count = 0\n","    saved_count = 0\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # 지정된 프레임 간격마다 저장\n","        if frame_count % frame_interval == 0:\n","            frame_filename = os.path.join(output_folder, f\"frame_{saved_count:05d}.jpg\")\n","            cv2.imwrite(frame_filename, frame)\n","            saved_count += 1\n","\n","        frame_count += 1\n","\n","    cap.release()\n","    print(f\"Frames saved to {output_folder}\")\n","\n","# 프레임 추출 실행\n","extract_frames(\"test_video_1.mp4\", output_folder=\"test_frames_1\", frame_interval=5)\n","extract_frames(\"test_video_2.mp4\", output_folder=\"test_frames_2\", frame_interval=5)\n","extract_frames(\"test_video_5.mp4\", output_folder=\"test_frames_5\", frame_interval=5)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4331,"status":"ok","timestamp":1734069596837,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"6j_BqNsJKiuS","outputId":"65619be6-b20f-49a9-d4c8-f4bf0a8a5172","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 1 person, 9.7ms\n","Speed: 1.4ms preprocess, 9.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.7ms\n","Speed: 1.4ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00000.jpg\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.4ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.5ms\n","Speed: 1.3ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00001.jpg\n","\n","0: 384x640 1 person, 7.7ms\n","Speed: 1.3ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.7ms\n","Speed: 1.3ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00002.jpg\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.1ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.5ms\n","Speed: 1.4ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00003.jpg\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.5ms\n","Speed: 1.3ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00004.jpg\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.4ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00005.jpg\n","\n","0: 384x640 1 person, 7.6ms\n","Speed: 1.4ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.2ms\n","Speed: 1.4ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00006.jpg\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.3ms preprocess, 7.5ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.9ms\n","Speed: 1.4ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00007.jpg\n","\n","0: 384x640 1 person, 8.4ms\n","Speed: 1.5ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.5ms\n","Speed: 1.6ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00008.jpg\n","\n","0: 384x640 1 person, 7.5ms\n","Speed: 1.4ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.6ms\n","Speed: 0.9ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00009.jpg\n","\n","0: 384x640 1 person, 7.5ms\n","Speed: 1.3ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00010.jpg\n","\n","0: 384x640 1 person, 7.5ms\n","Speed: 1.1ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 0.9ms preprocess, 7.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00011.jpg\n","\n","0: 384x640 1 person, 7.9ms\n","Speed: 1.1ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.2ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00012.jpg\n","\n","0: 384x640 1 person, 7.9ms\n","Speed: 1.4ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.3ms\n","Speed: 1.0ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00013.jpg\n","\n","0: 384x640 1 person, 7.5ms\n","Speed: 1.3ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.4ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00014.jpg\n","\n","0: 384x640 1 person, 7.6ms\n","Speed: 1.3ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.1ms\n","Speed: 2.0ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00015.jpg\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.3ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.4ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00016.jpg\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.5ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.7ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00017.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.5ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00018.jpg\n","\n","0: 384x640 (no detections), 9.1ms\n","Speed: 1.5ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.4ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00019.jpg\n","\n","0: 384x640 1 person, 7.7ms\n","Speed: 1.4ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 2.4ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00020.jpg\n","\n","0: 384x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.4ms\n","Speed: 1.7ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00021.jpg\n","\n","0: 384x640 1 person, 7.9ms\n","Speed: 1.5ms preprocess, 7.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.1ms\n","Speed: 1.6ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00022.jpg\n","\n","0: 384x640 1 person, 7.7ms\n","Speed: 1.6ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.6ms\n","Speed: 1.0ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00023.jpg\n","\n","0: 384x640 1 person, 8.2ms\n","Speed: 1.4ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.2ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00024.jpg\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.4ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.1ms\n","Speed: 1.5ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00025.jpg\n","\n","0: 384x640 1 person, 7.6ms\n","Speed: 1.3ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.4ms\n","Speed: 1.3ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00026.jpg\n","\n","0: 384x640 1 person, 8.1ms\n","Speed: 1.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.9ms\n","Speed: 1.3ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00027.jpg\n","\n","0: 384x640 1 person, 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.3ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00028.jpg\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.3ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00029.jpg\n","\n","0: 384x640 (no detections), 7.4ms\n","Speed: 1.3ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.4ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00030.jpg\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.7ms\n","Speed: 1.4ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00031.jpg\n","\n","0: 384x640 (no detections), 8.6ms\n","Speed: 1.1ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.5ms\n","Speed: 1.5ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00032.jpg\n","\n","0: 384x640 (no detections), 10.9ms\n","Speed: 1.5ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.6ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00033.jpg\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.3ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00034.jpg\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 1.2ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.0ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00035.jpg\n","\n","0: 384x640 (no detections), 8.6ms\n","Speed: 1.4ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.7ms\n","Speed: 1.5ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00036.jpg\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.7ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.0ms\n","Speed: 2.6ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00037.jpg\n","\n","0: 384x640 (no detections), 7.4ms\n","Speed: 1.5ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 2.4ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00038.jpg\n","\n","0: 384x640 (no detections), 7.4ms\n","Speed: 1.3ms preprocess, 7.4ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.4ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00039.jpg\n","\n","0: 384x640 (no detections), 8.1ms\n","Speed: 1.4ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.0ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00040.jpg\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.3ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00041.jpg\n","\n","0: 384x640 (no detections), 9.2ms\n","Speed: 1.5ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.6ms preprocess, 7.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00042.jpg\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.2ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.7ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00043.jpg\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.1ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.4ms\n","Speed: 1.0ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00044.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.5ms preprocess, 7.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 1.5ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00045.jpg\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 1.5ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.0ms preprocess, 7.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00046.jpg\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 1.3ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.2ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00047.jpg\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.3ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.5ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00048.jpg\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.4ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.4ms\n","Speed: 1.4ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00049.jpg\n","\n","0: 384x640 (no detections), 9.8ms\n","Speed: 1.4ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.8ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00050.jpg\n","\n","0: 384x640 (no detections), 8.2ms\n","Speed: 1.7ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.9ms\n","Speed: 1.5ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00051.jpg\n","\n","0: 384x640 (no detections), 9.3ms\n","Speed: 1.4ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.3ms\n","Speed: 1.4ms preprocess, 8.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00052.jpg\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.3ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.0ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00053.jpg\n","\n","0: 384x640 (no detections), 8.7ms\n","Speed: 1.2ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.1ms\n","Speed: 1.6ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00054.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.4ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.5ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00055.jpg\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.4ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.4ms\n","Speed: 1.7ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00056.jpg\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.2ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.6ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00057.jpg\n","\n","0: 384x640 (no detections), 8.7ms\n","Speed: 1.5ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.5ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00058.jpg\n","\n","0: 384x640 (no detections), 8.3ms\n","Speed: 1.5ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.5ms\n","Speed: 2.2ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00059.jpg\n","\n","0: 384x640 (no detections), 8.2ms\n","Speed: 1.2ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.9ms\n","Speed: 1.3ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00060.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10.2ms\n","Speed: 1.8ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00061.jpg\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.3ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.2ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00062.jpg\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.2ms preprocess, 7.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.2ms\n","Speed: 1.7ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00063.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.0ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00064.jpg\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.4ms\n","Speed: 1.5ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00065.jpg\n","\n","0: 384x640 (no detections), 9.1ms\n","Speed: 1.3ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.9ms\n","Speed: 1.0ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00066.jpg\n","\n","0: 384x640 (no detections), 9.2ms\n","Speed: 1.6ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.3ms\n","Speed: 1.6ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00067.jpg\n","\n","0: 384x640 (no detections), 9.1ms\n","Speed: 1.4ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.3ms\n","Speed: 2.3ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00068.jpg\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.5ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.5ms\n","Speed: 1.5ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00069.jpg\n","\n","0: 384x640 (no detections), 8.3ms\n","Speed: 1.6ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.4ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00070.jpg\n","\n","0: 384x640 (no detections), 7.4ms\n","Speed: 1.4ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.4ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00071.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.4ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.4ms\n","Speed: 1.0ms preprocess, 8.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00072.jpg\n","\n","0: 384x640 (no detections), 8.6ms\n","Speed: 1.2ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.8ms\n","Speed: 1.5ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00073.jpg\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.3ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.4ms\n","Speed: 1.5ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00074.jpg\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.6ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.1ms\n","Speed: 1.6ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00075.jpg\n","\n","0: 384x640 (no detections), 8.2ms\n","Speed: 1.2ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.7ms\n","Speed: 1.5ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00076.jpg\n","\n","0: 384x640 (no detections), 8.3ms\n","Speed: 1.0ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.1ms\n","Speed: 1.7ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00077.jpg\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00078.jpg\n","\n","0: 384x640 (no detections), 8.1ms\n","Speed: 1.4ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.0ms\n","Speed: 1.7ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00079.jpg\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.9ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.6ms\n","Speed: 1.1ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00080.jpg\n","\n","0: 384x640 (no detections), 8.8ms\n","Speed: 1.3ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.2ms\n","Speed: 1.6ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00081.jpg\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 1.5ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.5ms\n","Speed: 1.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00082.jpg\n","\n","0: 384x640 (no detections), 8.3ms\n","Speed: 1.4ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.1ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00083.jpg\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 2.0ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.9ms\n","Speed: 1.3ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00084.jpg\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.3ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9.3ms\n","Speed: 0.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00085.jpg\n","\n","0: 384x640 (no detections), 9.9ms\n","Speed: 1.3ms preprocess, 9.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9.8ms\n","Speed: 1.5ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00086.jpg\n","\n","0: 384x640 (no detections), 8.4ms\n","Speed: 1.4ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9.1ms\n","Speed: 1.6ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00087.jpg\n","\n","0: 384x640 (no detections), 8.2ms\n","Speed: 1.3ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 14.0ms\n","Speed: 1.5ms preprocess, 14.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00088.jpg\n","\n","0: 384x640 (no detections), 8.2ms\n","Speed: 1.5ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10.1ms\n","Speed: 1.6ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00089.jpg\n","\n","0: 384x640 (no detections), 10.5ms\n","Speed: 1.9ms preprocess, 10.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 13.0ms\n","Speed: 1.8ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00090.jpg\n","\n","0: 384x640 1 person, 10.0ms\n","Speed: 2.2ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.2ms\n","Speed: 1.8ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00091.jpg\n","\n","0: 384x640 1 person, 10.1ms\n","Speed: 1.5ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.8ms\n","Speed: 1.5ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00092.jpg\n","\n","0: 384x640 1 person, 10.3ms\n","Speed: 1.8ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 13.7ms\n","Speed: 2.2ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00093.jpg\n","\n","0: 384x640 1 person, 9.7ms\n","Speed: 1.9ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 12.3ms\n","Speed: 1.9ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00094.jpg\n","\n","0: 384x640 (no detections), 8.1ms\n","Speed: 1.6ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.3ms\n","Speed: 2.0ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00095.jpg\n","\n","0: 384x640 (no detections), 8.7ms\n","Speed: 1.5ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 9.6ms\n","Speed: 2.1ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00096.jpg\n","\n","0: 384x640 (no detections), 8.6ms\n","Speed: 1.5ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.3ms\n","Speed: 1.3ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00097.jpg\n","\n","0: 384x640 (no detections), 9.6ms\n","Speed: 1.4ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.5ms\n","Speed: 1.5ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00098.jpg\n","\n","0: 384x640 (no detections), 8.5ms\n","Speed: 1.3ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.7ms\n","Speed: 1.4ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00099.jpg\n","\n","0: 384x640 (no detections), 7.4ms\n","Speed: 1.3ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.0ms\n","Speed: 2.1ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00100.jpg\n","\n","0: 384x640 1 person, 9.0ms\n","Speed: 1.4ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8.2ms\n","Speed: 1.6ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00101.jpg\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.6ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.6ms\n","Speed: 1.4ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00102.jpg\n","\n","0: 384x640 (no detections), 8.3ms\n","Speed: 1.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.3ms\n","Speed: 1.5ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00103.jpg\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.9ms\n","Speed: 1.3ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00104.jpg\n","\n","0: 384x640 1 person, 7.9ms\n","Speed: 1.8ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.3ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00105.jpg\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.3ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00106.jpg\n","\n","0: 384x640 1 person, 7.6ms\n","Speed: 1.4ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.3ms\n","Speed: 2.1ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00107.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.0ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.5ms\n","Speed: 1.3ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00108.jpg\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.7ms\n","Speed: 1.5ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00109.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.3ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.7ms\n","Speed: 1.2ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00110.jpg\n","\n","0: 384x640 (no detections), 9.0ms\n","Speed: 1.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.4ms\n","Speed: 1.7ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00111.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.2ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.3ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00112.jpg\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.4ms preprocess, 7.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.1ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00113.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.3ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 0.9ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00114.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.0ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.3ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00115.jpg\n","\n","0: 384x640 (no detections), 7.4ms\n","Speed: 1.3ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 0.9ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00116.jpg\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.6ms\n","Speed: 0.9ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00117.jpg\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.2ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00118.jpg\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.3ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.5ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00119.jpg\n","\n","0: 384x640 (no detections), 8.5ms\n","Speed: 1.5ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.8ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00120.jpg\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.4ms preprocess, 7.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.2ms\n","Speed: 1.8ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00121.jpg\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.6ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.0ms\n","Speed: 1.5ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00122.jpg\n","\n","0: 384x640 (no detections), 10.0ms\n","Speed: 1.2ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.4ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00123.jpg\n","\n","0: 384x640 (no detections), 9.7ms\n","Speed: 1.4ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.5ms\n","Speed: 1.6ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00124.jpg\n","\n","0: 384x640 (no detections), 8.5ms\n","Speed: 2.0ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.9ms\n","Speed: 1.0ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00125.jpg\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.5ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.2ms\n","Speed: 1.6ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00126.jpg\n","\n","0: 384x640 (no detections), 10.7ms\n","Speed: 1.7ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.7ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00127.jpg\n","\n","0: 384x640 (no detections), 8.3ms\n","Speed: 1.4ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.9ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00128.jpg\n","\n","0: 384x640 (no detections), 7.7ms\n","Speed: 1.6ms preprocess, 7.7ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.5ms preprocess, 7.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00129.jpg\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.4ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.1ms\n","Speed: 1.5ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00130.jpg\n","\n","0: 384x640 (no detections), 7.6ms\n","Speed: 1.0ms preprocess, 7.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.6ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00131.jpg\n","\n","0: 384x640 (no detections), 7.5ms\n","Speed: 1.5ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.6ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00132.jpg\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.6ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 0.9ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00133.jpg\n","\n","0: 384x640 (no detections), 8.0ms\n","Speed: 1.2ms preprocess, 8.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 11.2ms\n","Speed: 1.6ms preprocess, 11.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00134.jpg\n","\n","0: 384x640 (no detections), 8.2ms\n","Speed: 1.5ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 9.4ms\n","Speed: 1.8ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00135.jpg\n","\n","0: 384x640 (no detections), 7.8ms\n","Speed: 1.3ms preprocess, 7.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 2.3ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00136.jpg\n","\n","0: 384x640 (no detections), 8.1ms\n","Speed: 1.3ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 7.9ms\n","Speed: 1.1ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00137.jpg\n","\n","0: 384x640 (no detections), 8.1ms\n","Speed: 1.4ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 (no detections), 8.3ms\n","Speed: 1.6ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n","Warning: Bed edges not detected for image frame_00138.jpg\n"]}],"source":["import cv2\n","import numpy as np\n","\n","# Extract bed edges (outline only)\n","def extract_bed_edges(mask):\n","    mask = mask.astype(np.uint8) * 255  # Convert to binary image\n","    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    edge_coords = []\n","    for contour in contours:\n","        for point in contour:\n","            edge_coords.append(point[0])  # Append x, y coordinates\n","    return edge_coords\n","\n","bed_edges_list = []\n","\n","for image_path in image_paths:\n","    # Load image\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Error: Unable to load image {image_path}\")\n","        continue\n","\n","    # Model inference\n","    try:\n","        seg_results = model(image, conf=0.5, iou=0.4)\n","        pose_results = pose_model(image)\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        continue\n","\n","    # Extract Segmentation Masks\n","    masks = seg_results[0].masks.data.cpu().numpy() if seg_results[0].masks is not None else []\n","    pose_keypoints = pose_results[0].keypoints.data.cpu().numpy() if pose_results[0].keypoints is not None else None\n","    bed_mask = None\n","\n","    # Filter bed mask\n","    if seg_results[0].boxes is not None:\n","        classes = seg_results[0].boxes.cls.cpu().numpy()\n","        for i, cls in enumerate(classes):\n","            if cls == 1:  # Assuming 1 is the bed class ID\n","                bed_mask = masks[i]\n","\n","    # Process bed mask\n","    bed_edges = None\n","    if bed_mask is not None:\n","        bed_mask_resized = cv2.resize(bed_mask, (image.shape[1], image.shape[0]))\n","        mask_bool = bed_mask_resized > 0.5\n","        bed_edges = extract_bed_edges(mask_bool)\n","\n","    # Skip if bed edges are not detected\n","    if bed_edges is None or len(bed_edges) == 0:\n","        print(f\"Warning: Bed edges not detected for image {os.path.basename(image_path)}\")\n","        continue\n","\n","    # Extract keypoints and check exact match\n","    keypoints = []\n","    keypoints_on_bed_edge = 0  # Counter for keypoints exactly on the bed edge\n","\n","    if pose_keypoints is not None and len(pose_keypoints[0]) > 0:\n","        for kp in pose_keypoints[0]:\n","            x, y, conf = kp\n","            if conf > 0.5:  # Filter based on confidence\n","                x_original = int(x)\n","                y_original = int(y)\n","\n","                # Check exact match with bed edge coordinates\n","                exact_match = any((x_original == edge[0] and y_original == edge[1]) for edge in bed_edges)\n","                if exact_match:\n","                    keypoints_on_bed_edge += 1\n","\n","                keypoints.append({\"x\": x_original, \"y\": y_original, \"conf\": conf, \"on_bed_edge\": exact_match})\n","\n","    # Append data to list\n","    bed_edges_list.append({\n","        \"image\": os.path.basename(image_path),\n","        \"keypoints\": keypoints,\n","        \"keypoints_on_bed_edge\": keypoints_on_bed_edge\n","    })\n","\n","# Output results\n","for entry in bed_edges_list:\n","    print(f\"Image: {entry['image']}\")\n","    if entry[\"keypoints\"]:\n","        print(\"  Keypoints:\")\n","        for kp in entry[\"keypoints\"]:\n","            print(f\"    (X: {kp['x']}, Y: {kp['y']}, Confidence: {kp['conf']}, On Bed Edge: {kp['on_bed_edge']})\")\n","    else:\n","        print(\"  No keypoints detected.\")\n","    print(f\"  Total Keypoints On Bed Edge: {entry['keypoints_on_bed_edge']}\")\n"]},{"cell_type":"markdown","metadata":{"id":"1fVtDiv9SxqZ"},"source":["#### 최종코드 + 움직임 코드"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":282,"status":"ok","timestamp":1734072869462,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"xg1hw1MNRnBT","outputId":"cad2488a-09f5-4264-beef-175e260657ae","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Copied: frame_00250.jpg\n","Copied: frame_00251.jpg\n","Copied: frame_00252.jpg\n","Copied: frame_00253.jpg\n","Copied: frame_00254.jpg\n","Copied: frame_00255.jpg\n","Copied: frame_00256.jpg\n","Copied: frame_00257.jpg\n","Copied: frame_00258.jpg\n","Copied: frame_00259.jpg\n","Copied: frame_00260.jpg\n","Copied: frame_00261.jpg\n","Copied: frame_00262.jpg\n","Copied: frame_00263.jpg\n","Copied: frame_00264.jpg\n","Copied: frame_00265.jpg\n","Copied: frame_00266.jpg\n","Copied: frame_00267.jpg\n","Copied: frame_00268.jpg\n","Copied: frame_00269.jpg\n","Copied: frame_00270.jpg\n","Copied: frame_00271.jpg\n","Copied: frame_00272.jpg\n","Copied: frame_00273.jpg\n","Copied: frame_00274.jpg\n","Copied: frame_00275.jpg\n","Copied: frame_00276.jpg\n","Copied: frame_00277.jpg\n","Copied: frame_00278.jpg\n","Copied: frame_00279.jpg\n","Copied: frame_00280.jpg\n","Copied: frame_00281.jpg\n","Copied: frame_00282.jpg\n","Copied: frame_00283.jpg\n","Copied: frame_00284.jpg\n","Copied: frame_00285.jpg\n","Copied: frame_00286.jpg\n","Copied: frame_00287.jpg\n","Copied: frame_00288.jpg\n","Copied: frame_00289.jpg\n","Copied: frame_00290.jpg\n","Copied: frame_00291.jpg\n","Copied: frame_00292.jpg\n","Copied: frame_00293.jpg\n","Copied: frame_00294.jpg\n","Copied: frame_00295.jpg\n","Copied: frame_00296.jpg\n","Copied: frame_00297.jpg\n","Copied: frame_00298.jpg\n","Copied: frame_00299.jpg\n","Copied: frame_00300.jpg\n","Copied: frame_00301.jpg\n","Copied: frame_00302.jpg\n","Copied: frame_00303.jpg\n","Copied: frame_00304.jpg\n","Copied: frame_00305.jpg\n","Copied: frame_00306.jpg\n","Copied: frame_00307.jpg\n","Copied: frame_00308.jpg\n","Copied: frame_00309.jpg\n","Copied: frame_00310.jpg\n","Copied: frame_00311.jpg\n","Copied: frame_00312.jpg\n","Copied: frame_00313.jpg\n","Copied: frame_00314.jpg\n","Copied: frame_00315.jpg\n","Copied: frame_00316.jpg\n","Copied: frame_00317.jpg\n","Copied: frame_00318.jpg\n","Copied: frame_00319.jpg\n","File extraction completed!\n"]}],"source":["import os\n","import shutil\n","\n","# 원본 디렉토리 및 대상 디렉토리 설정\n","source_dir = \"/content/test_frames_2\"\n","target_dir = \"/content/test_data\"\n","\n","# 대상 디렉토리 생성\n","os.makedirs(target_dir, exist_ok=True)\n","\n","# frame_00100 ~ frame_00200 파일 복사\n","for i in range(250, 320):  # 100부터 200까지 반복\n","    file_name = f\"frame_{i:05d}.jpg\"  # 파일명 형식에 맞게 설정\n","    source_path = os.path.join(source_dir, file_name)\n","    target_path = os.path.join(target_dir, file_name)\n","\n","    # 파일이 존재하면 복사\n","    if os.path.exists(source_path):\n","        shutil.copy(source_path, target_path)\n","        print(f\"Copied: {file_name}\")\n","    else:\n","        print(f\"File not found: {file_name}\")\n","\n","print(\"File extraction completed!\")\n"]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# 원본 디렉토리 및 대상 디렉토리 설정\n","source_dir = \"/content/test_frames_5\"\n","target_dir = \"/content/test_data\"\n","\n","# 대상 디렉토리 생성\n","os.makedirs(target_dir, exist_ok=True)\n","\n","# frame_00100 ~ frame_00200 파일 복사\n","for i in range(000, 123):  # 100부터 200까지 반복\n","    file_name = f\"frame_{i:05d}.jpg\"  # 파일명 형식에 맞게 설정\n","    source_path = os.path.join(source_dir, file_name)\n","    target_path = os.path.join(target_dir, file_name)\n","\n","    # 파일이 존재하면 복사\n","    if os.path.exists(source_path):\n","        shutil.copy(source_path, target_path)\n","        print(f\"Copied: {file_name}\")\n","    else:\n","        print(f\"File not found: {file_name}\")\n","\n","print(\"File extraction completed!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRSPdgiIyz5D","executionInfo":{"status":"ok","timestamp":1734072945134,"user_tz":-540,"elapsed":264,"user":{"displayName":"bbang","userId":"09004285429129758855"}},"outputId":"290e56e0-1f26-4df9-d338-0d2deeabd2cd","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copied: frame_00000.jpg\n","Copied: frame_00001.jpg\n","Copied: frame_00002.jpg\n","Copied: frame_00003.jpg\n","Copied: frame_00004.jpg\n","Copied: frame_00005.jpg\n","Copied: frame_00006.jpg\n","Copied: frame_00007.jpg\n","Copied: frame_00008.jpg\n","Copied: frame_00009.jpg\n","Copied: frame_00010.jpg\n","Copied: frame_00011.jpg\n","Copied: frame_00012.jpg\n","Copied: frame_00013.jpg\n","Copied: frame_00014.jpg\n","Copied: frame_00015.jpg\n","Copied: frame_00016.jpg\n","Copied: frame_00017.jpg\n","Copied: frame_00018.jpg\n","Copied: frame_00019.jpg\n","Copied: frame_00020.jpg\n","Copied: frame_00021.jpg\n","Copied: frame_00022.jpg\n","Copied: frame_00023.jpg\n","Copied: frame_00024.jpg\n","Copied: frame_00025.jpg\n","Copied: frame_00026.jpg\n","Copied: frame_00027.jpg\n","Copied: frame_00028.jpg\n","Copied: frame_00029.jpg\n","Copied: frame_00030.jpg\n","Copied: frame_00031.jpg\n","Copied: frame_00032.jpg\n","Copied: frame_00033.jpg\n","Copied: frame_00034.jpg\n","Copied: frame_00035.jpg\n","Copied: frame_00036.jpg\n","Copied: frame_00037.jpg\n","Copied: frame_00038.jpg\n","Copied: frame_00039.jpg\n","Copied: frame_00040.jpg\n","Copied: frame_00041.jpg\n","Copied: frame_00042.jpg\n","Copied: frame_00043.jpg\n","Copied: frame_00044.jpg\n","Copied: frame_00045.jpg\n","Copied: frame_00046.jpg\n","Copied: frame_00047.jpg\n","Copied: frame_00048.jpg\n","Copied: frame_00049.jpg\n","Copied: frame_00050.jpg\n","Copied: frame_00051.jpg\n","Copied: frame_00052.jpg\n","Copied: frame_00053.jpg\n","Copied: frame_00054.jpg\n","Copied: frame_00055.jpg\n","Copied: frame_00056.jpg\n","Copied: frame_00057.jpg\n","Copied: frame_00058.jpg\n","Copied: frame_00059.jpg\n","Copied: frame_00060.jpg\n","Copied: frame_00061.jpg\n","Copied: frame_00062.jpg\n","Copied: frame_00063.jpg\n","Copied: frame_00064.jpg\n","Copied: frame_00065.jpg\n","Copied: frame_00066.jpg\n","Copied: frame_00067.jpg\n","Copied: frame_00068.jpg\n","Copied: frame_00069.jpg\n","Copied: frame_00070.jpg\n","Copied: frame_00071.jpg\n","Copied: frame_00072.jpg\n","Copied: frame_00073.jpg\n","Copied: frame_00074.jpg\n","Copied: frame_00075.jpg\n","Copied: frame_00076.jpg\n","Copied: frame_00077.jpg\n","Copied: frame_00078.jpg\n","Copied: frame_00079.jpg\n","Copied: frame_00080.jpg\n","Copied: frame_00081.jpg\n","Copied: frame_00082.jpg\n","Copied: frame_00083.jpg\n","Copied: frame_00084.jpg\n","Copied: frame_00085.jpg\n","Copied: frame_00086.jpg\n","Copied: frame_00087.jpg\n","Copied: frame_00088.jpg\n","Copied: frame_00089.jpg\n","Copied: frame_00090.jpg\n","Copied: frame_00091.jpg\n","Copied: frame_00092.jpg\n","Copied: frame_00093.jpg\n","Copied: frame_00094.jpg\n","Copied: frame_00095.jpg\n","Copied: frame_00096.jpg\n","Copied: frame_00097.jpg\n","Copied: frame_00098.jpg\n","Copied: frame_00099.jpg\n","Copied: frame_00100.jpg\n","Copied: frame_00101.jpg\n","Copied: frame_00102.jpg\n","Copied: frame_00103.jpg\n","Copied: frame_00104.jpg\n","Copied: frame_00105.jpg\n","Copied: frame_00106.jpg\n","Copied: frame_00107.jpg\n","Copied: frame_00108.jpg\n","Copied: frame_00109.jpg\n","Copied: frame_00110.jpg\n","Copied: frame_00111.jpg\n","Copied: frame_00112.jpg\n","Copied: frame_00113.jpg\n","Copied: frame_00114.jpg\n","Copied: frame_00115.jpg\n","Copied: frame_00116.jpg\n","Copied: frame_00117.jpg\n","Copied: frame_00118.jpg\n","Copied: frame_00119.jpg\n","Copied: frame_00120.jpg\n","Copied: frame_00121.jpg\n","Copied: frame_00122.jpg\n","File extraction completed!\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# 원본 디렉토리 및 대상 디렉토리 설정\n","source_dir = \"/content/test_frames_3\"\n","target_dir = \"/content/sample_3\"\n","\n","# 대상 디렉토리 생성\n","os.makedirs(target_dir, exist_ok=True)\n","\n","# frame_00100 ~ frame_00200 파일 복사\n","for i in range(000, 139):  # 100부터 200까지 반복\n","    file_name = f\"frame_{i:05d}.jpg\"  # 파일명 형식에 맞게 설정\n","    source_path = os.path.join(source_dir, file_name)\n","    target_path = os.path.join(target_dir, file_name)\n","\n","    # 파일이 존재하면 복사\n","    if os.path.exists(source_path):\n","        shutil.copy(source_path, target_path)\n","        print(f\"Copied: {file_name}\")\n","    else:\n","        print(f\"File not found: {file_name}\")\n","\n","print(\"File extraction completed!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Lx0UHtRklzA","executionInfo":{"status":"ok","timestamp":1734069103481,"user_tz":-540,"elapsed":541,"user":{"displayName":"bbang","userId":"09004285429129758855"}},"outputId":"88a4350a-2111-4971-9787-89af18529e9c","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copied: frame_00000.jpg\n","Copied: frame_00001.jpg\n","Copied: frame_00002.jpg\n","Copied: frame_00003.jpg\n","Copied: frame_00004.jpg\n","Copied: frame_00005.jpg\n","Copied: frame_00006.jpg\n","Copied: frame_00007.jpg\n","Copied: frame_00008.jpg\n","Copied: frame_00009.jpg\n","Copied: frame_00010.jpg\n","Copied: frame_00011.jpg\n","Copied: frame_00012.jpg\n","Copied: frame_00013.jpg\n","Copied: frame_00014.jpg\n","Copied: frame_00015.jpg\n","Copied: frame_00016.jpg\n","Copied: frame_00017.jpg\n","Copied: frame_00018.jpg\n","Copied: frame_00019.jpg\n","Copied: frame_00020.jpg\n","Copied: frame_00021.jpg\n","Copied: frame_00022.jpg\n","Copied: frame_00023.jpg\n","Copied: frame_00024.jpg\n","Copied: frame_00025.jpg\n","Copied: frame_00026.jpg\n","Copied: frame_00027.jpg\n","Copied: frame_00028.jpg\n","Copied: frame_00029.jpg\n","Copied: frame_00030.jpg\n","Copied: frame_00031.jpg\n","Copied: frame_00032.jpg\n","Copied: frame_00033.jpg\n","Copied: frame_00034.jpg\n","Copied: frame_00035.jpg\n","Copied: frame_00036.jpg\n","Copied: frame_00037.jpg\n","Copied: frame_00038.jpg\n","Copied: frame_00039.jpg\n","Copied: frame_00040.jpg\n","Copied: frame_00041.jpg\n","Copied: frame_00042.jpg\n","Copied: frame_00043.jpg\n","Copied: frame_00044.jpg\n","Copied: frame_00045.jpg\n","Copied: frame_00046.jpg\n","Copied: frame_00047.jpg\n","Copied: frame_00048.jpg\n","Copied: frame_00049.jpg\n","Copied: frame_00050.jpg\n","Copied: frame_00051.jpg\n","Copied: frame_00052.jpg\n","Copied: frame_00053.jpg\n","Copied: frame_00054.jpg\n","Copied: frame_00055.jpg\n","Copied: frame_00056.jpg\n","Copied: frame_00057.jpg\n","Copied: frame_00058.jpg\n","Copied: frame_00059.jpg\n","Copied: frame_00060.jpg\n","Copied: frame_00061.jpg\n","Copied: frame_00062.jpg\n","Copied: frame_00063.jpg\n","Copied: frame_00064.jpg\n","Copied: frame_00065.jpg\n","Copied: frame_00066.jpg\n","Copied: frame_00067.jpg\n","Copied: frame_00068.jpg\n","Copied: frame_00069.jpg\n","Copied: frame_00070.jpg\n","Copied: frame_00071.jpg\n","Copied: frame_00072.jpg\n","Copied: frame_00073.jpg\n","Copied: frame_00074.jpg\n","Copied: frame_00075.jpg\n","Copied: frame_00076.jpg\n","Copied: frame_00077.jpg\n","Copied: frame_00078.jpg\n","Copied: frame_00079.jpg\n","Copied: frame_00080.jpg\n","Copied: frame_00081.jpg\n","Copied: frame_00082.jpg\n","Copied: frame_00083.jpg\n","Copied: frame_00084.jpg\n","Copied: frame_00085.jpg\n","Copied: frame_00086.jpg\n","Copied: frame_00087.jpg\n","Copied: frame_00088.jpg\n","Copied: frame_00089.jpg\n","Copied: frame_00090.jpg\n","Copied: frame_00091.jpg\n","Copied: frame_00092.jpg\n","Copied: frame_00093.jpg\n","Copied: frame_00094.jpg\n","Copied: frame_00095.jpg\n","Copied: frame_00096.jpg\n","Copied: frame_00097.jpg\n","Copied: frame_00098.jpg\n","Copied: frame_00099.jpg\n","Copied: frame_00100.jpg\n","Copied: frame_00101.jpg\n","Copied: frame_00102.jpg\n","Copied: frame_00103.jpg\n","Copied: frame_00104.jpg\n","Copied: frame_00105.jpg\n","Copied: frame_00106.jpg\n","Copied: frame_00107.jpg\n","Copied: frame_00108.jpg\n","Copied: frame_00109.jpg\n","Copied: frame_00110.jpg\n","Copied: frame_00111.jpg\n","Copied: frame_00112.jpg\n","Copied: frame_00113.jpg\n","Copied: frame_00114.jpg\n","Copied: frame_00115.jpg\n","Copied: frame_00116.jpg\n","Copied: frame_00117.jpg\n","Copied: frame_00118.jpg\n","Copied: frame_00119.jpg\n","Copied: frame_00120.jpg\n","Copied: frame_00121.jpg\n","Copied: frame_00122.jpg\n","Copied: frame_00123.jpg\n","Copied: frame_00124.jpg\n","Copied: frame_00125.jpg\n","Copied: frame_00126.jpg\n","Copied: frame_00127.jpg\n","Copied: frame_00128.jpg\n","Copied: frame_00129.jpg\n","Copied: frame_00130.jpg\n","Copied: frame_00131.jpg\n","Copied: frame_00132.jpg\n","Copied: frame_00133.jpg\n","Copied: frame_00134.jpg\n","Copied: frame_00135.jpg\n","Copied: frame_00136.jpg\n","Copied: frame_00137.jpg\n","Copied: frame_00138.jpg\n","File extraction completed!\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1yOrPdMfGNyDBjRxGP98n8CZAWrhDKyRc"},"executionInfo":{"elapsed":79698,"status":"ok","timestamp":1734064099399,"user":{"displayName":"bbang","userId":"09004285429129758855"},"user_tz":-540},"id":"OGFwM9e3Qgza","outputId":"25b942c0-e4a3-4e6e-ba3a-9380cb9abfe5"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import numpy as np\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","from ultralytics import YOLO\n","\n","# YOLOv8 Segmentation 모델 로드\n","model = YOLO('/content/drive/MyDrive/Seg_dataset/best.pt')  # Segmentation 모델\n","pose_model = YOLO('yolov8n-pose.pt')\n","\n","# 테스트 이미지 경로\n","test_images_dir = '/content/drive/MyDrive/baby_Prone'\n","image_paths = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith(('.jpg', '.png'))]\n","# COCO Keypoint 연결 정의\n","pose_connections = [\n","    (0, 1), (0, 2), (1, 3), (2, 4),  # 머리 연결\n","    (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # 팔 연결\n","    (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # 다리 연결\n","]\n","\n","# 뼈대 시각화 함수\n","def draw_pose_skeleton(image, keypoints, connections, img_shape, orig_shape):\n","    \"\"\"\n","    이미지에 뼈대를 시각화하는 함수\n","    \"\"\"\n","    for connection in connections:\n","        start_idx, end_idx = connection\n","        if start_idx >= len(keypoints) or end_idx >= len(keypoints):\n","            continue\n","\n","        # 시작점과 끝점 좌표 계산\n","        start_x, start_y, start_conf = keypoints[start_idx]\n","        end_x, end_y, end_conf = keypoints[end_idx]\n","        if start_conf < 0.5 or end_conf < 0.5:  # 신뢰도가 낮으면 생략\n","            continue\n","\n","        start_x = int(start_x * (img_shape[1] / orig_shape[1]))\n","        start_y = int(start_y * (img_shape[0] / orig_shape[0]))\n","        end_x = int(end_x * (img_shape[1] / orig_shape[1]))\n","        end_y = int(end_y * (img_shape[0] / orig_shape[0]))\n","\n","        # 유효한 Keypoint만 연결\n","        if start_x > 0 and start_y > 0 and end_x > 0 and end_y > 0:\n","            cv2.line(image, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)  # 노란색 선\n","\n","    return image\n","\n","# 키포인트 시각화 함수\n","def draw_keypoints(image, keypoints, img_shape, orig_shape):\n","    \"\"\"\n","    이미지에 키포인트를 점으로 시각화하는 함수\n","    \"\"\"\n","    for keypoint in keypoints:\n","        x, y, conf = keypoint\n","        if conf > 0.5:  # 신뢰도가 높은 키포인트만 표시\n","            x_original = int(x * (img_shape[1] / orig_shape[1]))\n","            y_original = int(y * (img_shape[0] / orig_shape[0]))\n","            cv2.circle(image, (x_original, y_original), 5, (0, 255, 0), -1)  # 초록색 점\n","    return image\n","\n","# 침대 마스크 보정 함수\n","def refine_bed_mask(image_shape, bed_mask, person_mask):\n","    \"\"\"\n","    침대 마스크가 없거나 작을 경우 person 마스크를 제외한 나머지를 침대 마스크로 인식.\n","    \"\"\"\n","    if bed_mask is None or np.sum(bed_mask) < 0.1 * (image_shape[0] * image_shape[1]):  # 10% 이하인 경우\n","        print(\"Refining bed mask using person mask...\")\n","        bed_mask = np.ones(image_shape[:2], dtype=np.uint8)  # 전체 영역을 1로 초기화\n","        if person_mask is not None:\n","            person_mask_resized = cv2.resize(person_mask, (image_shape[1], image_shape[0]))\n","            bed_mask[person_mask_resized > 0.5] = 0  # person 영역 제외\n","    return bed_mask\n","\n","# 침대 테두리 좌표 추출 함수\n","def extract_bed_edges(mask):\n","    mask = mask.astype(np.uint8) * 255  # 이진화\n","    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    edge_coords = []\n","    for contour in contours:\n","        for point in contour:\n","            edge_coords.append(point[0].tolist())  # (x, y) 좌표를 리스트로 추가\n","    return edge_coords\n","\n","# 윤곽선 분석 기반 뒤집기 자세 감지\n","def detect_prone_via_contour(person_mask):\n","    \"\"\"\n","    윤곽선 분석을 통해 둥근 형태(뒷통수)를 판별하여 뒤집기 자세 탐지.\n","    \"\"\"\n","    if person_mask is None:\n","        return False, \"No person mask available for contour analysis.\"\n","\n","    contours, _ = cv2.findContours((person_mask > 0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    if len(contours) > 0:\n","        contour = max(contours, key=cv2.contourArea)\n","        convexity = cv2.isContourConvex(contour)  # 윤곽선이 둥근지 확인\n","        if convexity:\n","            return True, \"Warning: Head contour detected as round (prone position).\"\n","    return False, \"Head contour not round (no prone detected).\"\n","\n","# 키포인트 기반 뒤집기 자세 감지\n","def detect_prone_via_keypoints(pose_keypoints):\n","    \"\"\"\n","    얼굴 Keypoints(눈, 코)가 모두 없는 경우 뒤집기 자세로 간주.\n","    \"\"\"\n","    if pose_keypoints is None or len(pose_keypoints) == 0:\n","        return False, \"Pose keypoints missing or incomplete.\"\n","\n","    try:\n","        nose = pose_keypoints[0][0]  # 코\n","        left_eye = pose_keypoints[0][1]  # 왼쪽 눈\n","        right_eye = pose_keypoints[0][2]  # 오른쪽 눈\n","    except IndexError:\n","        return False, \"Keypoints array does not contain sufficient data.\"\n","\n","    # Keypoints의 신뢰도 확인\n","    if nose[2] < 0.5 and left_eye[2] < 0.5 and right_eye[2] < 0.5:\n","        return True, \"Warning: Face keypoints missing (prone position detected)!\"\n","\n","    return False, \"No prone position detected via keypoints.\"\n","\n","# 위험 감지 함수\n","def detect_risk_with_edges(pose_keypoints, bed_edges, bed_min_x, bed_max_x, bed_min_y, bed_max_y):\n","    if pose_keypoints is None or len(pose_keypoints) == 0:\n","        return \"Cannot assess risk. Missing or incomplete keypoints.\"\n","\n","    if not bed_edges:\n","        return \"Cannot assess risk. Missing bed edges.\"\n","\n","    keypoints_on_edge = 0\n","    keypoints_outside_bed = 0\n","\n","    for keypoint in pose_keypoints[0]:\n","        x, y, conf = keypoint\n","        if conf < 0.5:  # 신뢰도 낮은 경우 생략\n","            continue\n","\n","        x_original = int(x)\n","        y_original = int(y)\n","\n","        # 1단계 위험: 키포인트가 침대 테두리와 정확히 동일한 위치에 있음\n","        if [x_original, y_original] in bed_edges:\n","            keypoints_on_edge += 1\n","\n","        # 2단계 위험: 키포인트가 침대 외부로 나감\n","        if not (bed_min_x <= x_original <= bed_max_x and bed_min_y <= y_original <= bed_max_y):\n","            keypoints_outside_bed += 1\n","\n","    if keypoints_outside_bed >= 2:\n","        return f\"Risk Level 2: {keypoints_outside_bed} keypoints are outside the bed.\"\n","    if keypoints_on_edge > 0:\n","        return f\"Risk Level 1: {keypoints_on_edge} keypoints are exactly on the bed edge.\"\n","\n","    return \"No risk detected.\"\n","\n","# 테스트 실행\n","for image_path in image_paths:\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Error: Unable to load image {image_path}\")\n","        continue\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # 모델 추론\n","    try:\n","        seg_results = model(image, conf=0.5, iou=0.4)  # IOU 임계값 설정\n","        pose_results = pose_model(image)  # Pose 추론\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        continue\n","\n","    # Segmentation Masks 및 Keypoints 추출\n","    masks = seg_results[0].masks.data.cpu().numpy() if seg_results[0].masks is not None else []\n","    pose_keypoints = pose_results[0].keypoints.data.cpu().numpy() if pose_results[0].keypoints is not None else None\n","\n","    # 침대 및 사람 마스크 필터링\n","    bed_class_id = 1\n","    person_class_id = 0\n","    bed_mask = None\n","    person_mask = None\n","\n","    if seg_results[0].boxes is not None:\n","        classes = seg_results[0].boxes.cls.cpu().numpy()\n","        for i, cls in enumerate(classes):\n","            if cls == bed_class_id:\n","                bed_mask = masks[i]\n","            elif cls == person_class_id:\n","                person_mask = masks[i]\n","\n","    # 침대 마스크 보정\n","    bed_mask = refine_bed_mask(image.shape, bed_mask, person_mask)\n","\n","    # 침대 테두리 추출\n","    bed_edges = []\n","    bed_min_x = bed_max_x = bed_min_y = bed_max_y = None\n","    if bed_mask is not None:\n","        bed_mask_resized = cv2.resize(bed_mask, (image.shape[1], image.shape[0]))\n","        mask_bool = bed_mask_resized > 0.5\n","        bed_edges = extract_bed_edges(mask_bool)\n","        bed_coords = np.argwhere(mask_bool)\n","        if bed_coords.size > 0:\n","            bed_min_y, bed_max_y = np.min(bed_coords[:, 0]), np.max(bed_coords[:, 0])\n","            bed_min_x, bed_max_x = np.min(bed_coords[:, 1]), np.max(bed_coords[:, 1])\n","\n","    # 위험 감지\n","    risk_message = detect_risk_with_edges(pose_keypoints, bed_edges, bed_min_x, bed_max_x, bed_min_y, bed_max_y)\n","\n","    # 뒤집기 자세 감지\n","    prone_contour_detected, contour_message = detect_prone_via_contour(person_mask)\n","    prone_keypoints_detected, keypoints_message = detect_prone_via_keypoints(pose_keypoints)\n","\n","    prone_message = contour_message if prone_contour_detected else keypoints_message\n","\n","    # 시각화\n","    mask_overlay = np.zeros_like(image, dtype=np.uint8)\n","    if bed_mask is not None:\n","        mask_overlay[mask_bool] = [255, 0, 0]  # 침대 마스크 (빨간색)\n","        if bed_min_x is not None and bed_min_y is not None:\n","            cv2.rectangle(mask_overlay, (bed_min_x, bed_min_y), (bed_max_x, bed_max_y), (255, 255, 0), 2)  # 테두리 (노란색)\n","\n","    blended_image = cv2.addWeighted(image, 0.7, mask_overlay, 0.3, 0)\n","    if pose_keypoints is not None:\n","        blended_image = draw_keypoints(blended_image, pose_keypoints[0], image.shape, pose_results[0].orig_shape)\n","        blended_image = draw_pose_skeleton(blended_image, pose_keypoints[0], pose_connections, image.shape, pose_results[0].orig_shape)\n","\n","    # 텍스트 출력\n","    cv2.putText(blended_image, f\"Risk: {risk_message}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n","    cv2.putText(blended_image, prone_message, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(blended_image)\n","    plt.title(f\"{os.path.basename(image_path)}\")\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","    # 로그 출력\n","    print(f\"Processed Image: {os.path.basename(image_path)}\")\n","    print(risk_message)\n","    print(prone_message)\n"]},{"cell_type":"code","source":["import numpy as np\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","from ultralytics import YOLO\n","\n","# YOLOv8 Segmentation 모델 로드\n","model = YOLO('/content/drive/MyDrive/Seg_dataset/best.pt')  # Segmentation 모델\n","pose_model = YOLO('yolov8n-pose.pt')\n","\n","# 테스트 이미지 경로\n","test_images_dir = '/content/sample_2'\n","image_paths = [os.path.join(test_images_dir, img) for img in sorted(os.listdir(test_images_dir)) if img.endswith(('.jpg', '.png'))]\n","\n","# COCO Keypoint 연결 정의\n","pose_connections = [\n","    (0, 1), (0, 2), (1, 3), (2, 4),  # 머리 연결\n","    (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # 팔 연결\n","    (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # 다리 연결\n","]\n","\n","# 뼈대 시각화 함수\n","def draw_pose_skeleton(image, keypoints, connections, img_shape, orig_shape):\n","    for connection in connections:\n","        start_idx, end_idx = connection\n","        if start_idx >= len(keypoints) or end_idx >= len(keypoints):\n","            continue\n","\n","        start_x, start_y, start_conf = keypoints[start_idx]\n","        end_x, end_y, end_conf = keypoints[end_idx]\n","        if start_conf < 0.5 or end_conf < 0.5:  # 신뢰도가 낮으면 생략\n","            continue\n","\n","        start_x = int(start_x * (img_shape[1] / orig_shape[1]))\n","        start_y = int(start_y * (img_shape[0] / orig_shape[0]))\n","        end_x = int(end_x * (img_shape[1] / orig_shape[1]))\n","        end_y = int(end_y * (img_shape[0] / orig_shape[0]))\n","\n","        cv2.line(image, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)  # 노란색 선\n","\n","    return image\n","\n","# 키포인트 시각화 함수\n","def draw_keypoints(image, keypoints, img_shape, orig_shape):\n","    for keypoint in keypoints:\n","        x, y, conf = keypoint\n","        if conf > 0.5:\n","            x_original = int(x * (img_shape[1] / orig_shape[1]))\n","            y_original = int(y * (img_shape[0] / orig_shape[0]))\n","            cv2.circle(image, (x_original, y_original), 5, (0, 255, 0), -1)  # 초록색 점\n","    return image\n","\n","# 침대 마스크 보정 함수\n","def refine_bed_mask(image_shape, bed_mask, person_mask):\n","    if bed_mask is None or np.sum(bed_mask) < 0.3 * (image_shape[0] * image_shape[1]):\n","        print(\"Refining bed mask using person mask...\")\n","        bed_mask = np.ones(image_shape[:2], dtype=np.uint8)\n","        if person_mask is not None:\n","            person_mask_resized = cv2.resize(person_mask, (image_shape[1], image_shape[0]))\n","            bed_mask[person_mask_resized > 0.5] = 0\n","    return bed_mask\n","\n","# 침대 테두리 좌표 추출 함수\n","def extract_bed_edges(mask):\n","    mask = mask.astype(np.uint8) * 255\n","    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    edge_coords = []\n","    for contour in contours:\n","        for point in contour:\n","            edge_coords.append(point[0].tolist())\n","    return edge_coords\n","\n","# 윤곽선 분석 기반 뒤집기 자세 감지\n","def detect_prone_via_contour(person_mask):\n","    if person_mask is None:\n","        return False, \"No person mask available for contour analysis.\"\n","\n","    contours, _ = cv2.findContours((person_mask > 0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    if len(contours) > 0:\n","        contour = max(contours, key=cv2.contourArea)\n","        convexity = cv2.isContourConvex(contour)\n","        if convexity:\n","            return True, \"Warning: Head contour detected as round (prone position).\"\n","    return False, \"Head contour not round (no prone detected).\"\n","\n","# 키포인트 기반 뒤집기 자세 감지\n","def detect_prone_via_keypoints(pose_keypoints):\n","    if pose_keypoints is None or len(pose_keypoints) == 0:\n","        return False, \"Pose keypoints missing or incomplete.\"\n","\n","    try:\n","        nose = pose_keypoints[0][0]\n","        left_eye = pose_keypoints[0][1]\n","        right_eye = pose_keypoints[0][2]\n","    except IndexError:\n","        return False, \"Keypoints array does not contain sufficient data.\"\n","\n","    if nose[2] < 0.5 and left_eye[2] < 0.5 and right_eye[2] < 0.5:\n","        return True, \"Warning: prone position detected!\"\n","\n","    return False, \"Lying position\"\n","\n","# 위험 감지 함수\n","def detect_risk_with_edges(pose_keypoints, bed_edges, bed_min_x, bed_max_x, bed_min_y, bed_max_y):\n","    if pose_keypoints is None or len(pose_keypoints) == 0:\n","        return \"Cannot assess risk. Missing or incomplete keypoints.\"\n","\n","    if not bed_edges:\n","        return \"Cannot assess risk. Missing bed edges.\"\n","\n","    keypoints_on_edge = 0\n","    keypoints_outside_bed = 0\n","\n","    for keypoint in pose_keypoints[0]:\n","        x, y, conf = keypoint\n","        if conf < 0.5:\n","            continue\n","\n","        x_original = int(x)\n","        y_original = int(y)\n","\n","        if [x_original, y_original] in bed_edges:\n","            keypoints_on_edge += 1\n","\n","        if not (bed_min_x <= x_original <= bed_max_x and bed_min_y <= y_original <= bed_max_y):\n","            keypoints_outside_bed += 1\n","\n","    if keypoints_outside_bed >= 2:\n","        return f\"Risk Level 2: {keypoints_outside_bed} keypoints are outside the bed.\"\n","    if keypoints_on_edge > 0:\n","        return f\"Risk Level 1: {keypoints_on_edge} keypoints are exactly on the bed edge.\"\n","\n","    return \"No risk detected.\"\n","\n","# 움직임 감지 변수 초기화\n","previous_keypoints = None\n","no_motion_time = 0\n","frame_interval = 1 / 30\n","\n","# 테스트 실행\n","for image_path in image_paths:\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Error: Unable to load image {image_path}\")\n","        continue\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    try:\n","        seg_results = model(image, conf=0.5, iou=0.4)\n","        pose_results = pose_model(image)\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        continue\n","\n","    masks = seg_results[0].masks.data.cpu().numpy() if seg_results[0].masks is not None else []\n","    pose_keypoints = pose_results[0].keypoints.data.cpu().numpy() if pose_results[0].keypoints is not None else None\n","\n","    bed_class_id = 1\n","    person_class_id = 0\n","    bed_mask = None\n","    person_mask = None\n","\n","    if seg_results[0].boxes is not None:\n","        classes = seg_results[0].boxes.cls.cpu().numpy()\n","        for i, cls in enumerate(classes):\n","            if cls == bed_class_id:\n","                bed_mask = masks[i]\n","            elif cls == person_class_id:\n","                person_mask = masks[i]\n","\n","    bed_mask = refine_bed_mask(image.shape, bed_mask, person_mask)\n","\n","    bed_edges = []\n","    bed_min_x = bed_max_x = bed_min_y = bed_max_y = None\n","    if bed_mask is not None:\n","        bed_mask_resized = cv2.resize(bed_mask, (image.shape[1], image.shape[0]))\n","        mask_bool = bed_mask_resized > 0.5\n","        bed_edges = extract_bed_edges(mask_bool)\n","        bed_coords = np.argwhere(mask_bool)\n","        if bed_coords.size > 0:\n","            bed_min_y, bed_max_y = np.min(bed_coords[:, 0]), np.max(bed_coords[:, 0])\n","            bed_min_x, bed_max_x = np.min(bed_coords[:, 1]), np.max(bed_coords[:, 1])\n","\n","    motion_detected = False\n","    if pose_keypoints is not None and len(pose_keypoints) > 0 and previous_keypoints is not None and len(previous_keypoints) > 0:\n","        try:\n","            differences = np.linalg.norm(previous_keypoints[0][:, :2] - pose_keypoints[0][:, :2], axis=1)\n","            if np.any(differences > 5):\n","                motion_detected = True\n","                no_motion_time = 0\n","        except ValueError:\n","            print(\"Keypoint arrays have mismatched shapes.\")\n","    else:\n","        motion_detected = True  # Assume motion if keypoints are unavailable\n","\n","    if not motion_detected:\n","        no_motion_time += frame_interval\n","    else:\n","        no_motion_time = 0\n","\n","\n","    previous_keypoints = pose_keypoints\n","\n","    risk_message = detect_risk_with_edges(pose_keypoints, bed_edges, bed_min_x, bed_max_x, bed_min_y, bed_max_y)\n","\n","    prone_contour_detected, contour_message = detect_prone_via_contour(person_mask)\n","    prone_keypoints_detected, keypoints_message = detect_prone_via_keypoints(pose_keypoints)\n","\n","    prone_detected = prone_contour_detected or prone_keypoints_detected\n","\n","    if no_motion_time >= 90 and prone_detected:\n","        choking_status = \"Choking Risk Detected!\"\n","    else:\n","        choking_status = \"Safe & Moving\"\n","\n","    mask_overlay = np.zeros_like(image, dtype=np.uint8)\n","    if bed_mask is not None:\n","        mask_overlay[mask_bool] = [255, 0, 0]\n","        if bed_min_x is not None and bed_min_y is not None:\n","            cv2.rectangle(mask_overlay, (bed_min_x, bed_min_y), (bed_max_x, bed_max_y), (255, 255, 0), 2)\n","\n","    blended_image = cv2.addWeighted(image, 0.7, mask_overlay, 0.3, 0)\n","    if pose_keypoints is not None:\n","        blended_image = draw_keypoints(blended_image, pose_keypoints[0], image.shape, pose_results[0].orig_shape)\n","        blended_image = draw_pose_skeleton(blended_image, pose_keypoints[0], pose_connections, image.shape, pose_results[0].orig_shape)\n","\n","    cv2.putText(blended_image, f\"Choke: {choking_status}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n","        # 텍스트 출력\n","    cv2.putText(blended_image, f\"Fall: {risk_message}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n","    cv2.putText(blended_image, prone_message, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(blended_image)\n","    plt.title(f\"{os.path.basename(image_path)}\")\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","    print(f\"Processed Image: {os.path.basename(image_path)}\")\n","    print(f\"Choking Status: {choking_status}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1BUAxuUB-xIzCYenXoBiYdHvOx8-A6dmC"},"id":"1TbE4uWUX9lB","executionInfo":{"status":"error","timestamp":1734070352648,"user_tz":-540,"elapsed":21306,"user":{"displayName":"bbang","userId":"09004285429129758855"}},"outputId":"a09bb76b-d15c-41ec-f8db-354b123124e1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["import numpy as np\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","from ultralytics import YOLO\n","\n","# YOLOv8 Segmentation 모델 로드\n","model = YOLO('/content/drive/MyDrive/Seg_dataset/best.pt')  # Segmentation 모델\n","pose_model = YOLO('yolov8n-pose.pt')\n","\n","# 테스트 이미지 경로\n","test_images_dir = '/content/test_frames_5'\n","image_paths = [os.path.join(test_images_dir, img) for img in sorted(os.listdir(test_images_dir)) if img.endswith(('.jpg', '.png'))]\n","\n","# COCO Keypoint 연결 정의\n","pose_connections = [\n","    (0, 1), (0, 2), (1, 3), (2, 4),  # 머리 연결\n","    (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # 팔 연결\n","    (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # 다리 연결\n","]\n","\n","# 뼈대 시각화 함수\n","def draw_pose_skeleton(image, keypoints, connections, img_shape, orig_shape):\n","    for connection in connections:\n","        start_idx, end_idx = connection\n","        if start_idx >= len(keypoints) or end_idx >= len(keypoints):\n","            continue\n","\n","        start_x, start_y, start_conf = keypoints[start_idx]\n","        end_x, end_y, end_conf = keypoints[end_idx]\n","        if start_conf < 0.5 or end_conf < 0.5:  # 신뢰도가 낮으면 생략\n","            continue\n","\n","        start_x = int(start_x * (img_shape[1] / orig_shape[1]))\n","        start_y = int(start_y * (img_shape[0] / orig_shape[0]))\n","        end_x = int(end_x * (img_shape[1] / orig_shape[1]))\n","        end_y = int(end_y * (img_shape[0] / orig_shape[0]))\n","\n","        cv2.line(image, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)  # 노란색 선\n","\n","    return image\n","\n","# 키포인트 시각화 함수\n","def draw_keypoints(image, keypoints, img_shape, orig_shape):\n","    for keypoint in keypoints:\n","        x, y, conf = keypoint\n","        if conf > 0.5:\n","            x_original = int(x * (img_shape[1] / orig_shape[1]))\n","            y_original = int(y * (img_shape[0] / orig_shape[0]))\n","            cv2.circle(image, (x_original, y_original), 5, (0, 255, 0), -1)  # 초록색 점\n","    return image\n","\n","# 침대 마스크 보정 함수\n","def refine_bed_mask(image_shape, bed_mask, person_mask):\n","    if bed_mask is None or np.sum(bed_mask) < 0.1 * (image_shape[0] * image_shape[1]):\n","        print(\"Refining bed mask using person mask...\")\n","        bed_mask = np.ones(image_shape[:2], dtype=np.uint8)\n","        if person_mask is not None:\n","            person_mask_resized = cv2.resize(person_mask, (image_shape[1], image_shape[0]))\n","            bed_mask[person_mask_resized > 0.5] = 0\n","    return bed_mask\n","\n","# 침대 테두리 좌표 추출 함수\n","def extract_bed_edges(mask):\n","    mask = mask.astype(np.uint8) * 255\n","    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    edge_coords = []\n","    for contour in contours:\n","        for point in contour:\n","            edge_coords.append(point[0].tolist())\n","    return edge_coords\n","\n","# 윤곽선 분석 기반 뒤집기 자세 감지\n","def detect_prone_via_contour(person_mask):\n","    if person_mask is None:\n","        return False, \"No person mask available for contour analysis.\"\n","\n","    contours, _ = cv2.findContours((person_mask > 0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    if len(contours) > 0:\n","        contour = max(contours, key=cv2.contourArea)\n","        convexity = cv2.isContourConvex(contour)\n","        if convexity:\n","            return True, \"Warning: Head contour detected as round (prone position).\"\n","    return False, \"Head contour not round (no prone detected).\"\n","\n","# 키포인트 기반 뒤집기 자세 감지\n","def detect_prone_via_keypoints(pose_keypoints):\n","    if pose_keypoints is None or len(pose_keypoints) == 0:\n","        return False, \"Pose keypoints missing or incomplete.\"\n","\n","    try:\n","        nose = pose_keypoints[0][0]\n","        left_eye = pose_keypoints[0][1]\n","        right_eye = pose_keypoints[0][2]\n","    except IndexError:\n","        return False, \"Keypoints array does not contain sufficient data.\"\n","\n","    if nose[2] < 0.5 and left_eye[2] < 0.5 and right_eye[2] < 0.5:\n","        return True, \"Warning: prone position detected!\"\n","\n","    return False, \"Lying position\"\n","\n","# 위험 감지 함수\n","def detect_risk_with_edges(pose_keypoints, bed_edges, bed_min_x, bed_max_x, bed_min_y, bed_max_y):\n","    if pose_keypoints is None or len(pose_keypoints) == 0:\n","        return \"Cannot assess risk. Missing or incomplete keypoints.\"\n","\n","    if not bed_edges:\n","        return \"Cannot assess risk. Missing bed edges.\"\n","\n","    keypoints_on_edge = 0\n","    keypoints_outside_bed = 0\n","\n","    for keypoint in pose_keypoints[0]:\n","        x, y, conf = keypoint\n","        if conf < 0.5:\n","            continue\n","\n","        x_original = int(x)\n","        y_original = int(y)\n","\n","        if [x_original, y_original] in bed_edges:\n","            keypoints_on_edge += 1\n","\n","        if not (bed_min_x <= x_original <= bed_max_x and bed_min_y <= y_original <= bed_max_y):\n","            keypoints_outside_bed += 1\n","\n","    if keypoints_outside_bed >= 2:\n","        return f\"Risk Level 2: {keypoints_outside_bed} keypoints are outside the bed.\"\n","    if keypoints_on_edge > 0:\n","        return f\"Risk Level 1: {keypoints_on_edge} keypoints are exactly on the bed edge.\"\n","\n","    return \"No risk detected.\"\n","\n","# 움직임 감지 변수 초기화\n","previous_keypoints = None\n","no_motion_time = 0\n","frame_interval = 1 / 30\n","\n","# 테스트 실행\n","for image_path in image_paths:\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Error: Unable to load image {image_path}\")\n","        continue\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    try:\n","        seg_results = model(image, conf=0.5, iou=0.4)\n","        pose_results = pose_model(image)\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        continue\n","\n","    masks = seg_results[0].masks.data.cpu().numpy() if seg_results[0].masks is not None else []\n","    pose_keypoints = pose_results[0].keypoints.data.cpu().numpy() if pose_results[0].keypoints is not None else None\n","\n","    bed_class_id = 1\n","    person_class_id = 0\n","    bed_mask = None\n","    person_mask = None\n","\n","    if seg_results[0].boxes is not None:\n","        classes = seg_results[0].boxes.cls.cpu().numpy()\n","        for i, cls in enumerate(classes):\n","            if cls == bed_class_id:\n","                bed_mask = masks[i]\n","            elif cls == person_class_id:\n","                person_mask = masks[i]\n","\n","    bed_mask = refine_bed_mask(image.shape, bed_mask, person_mask)\n","\n","    bed_edges = []\n","    bed_min_x = bed_max_x = bed_min_y = bed_max_y = None\n","    if bed_mask is not None:\n","        bed_mask_resized = cv2.resize(bed_mask, (image.shape[1], image.shape[0]))\n","        mask_bool = bed_mask_resized > 0.5\n","        bed_edges = extract_bed_edges(mask_bool)\n","        bed_coords = np.argwhere(mask_bool)\n","        if bed_coords.size > 0:\n","            bed_min_y, bed_max_y = np.min(bed_coords[:, 0]), np.max(bed_coords[:, 0])\n","            bed_min_x, bed_max_x = np.min(bed_coords[:, 1]), np.max(bed_coords[:, 1])\n","\n","    motion_detected = False\n","    if pose_keypoints is not None and len(pose_keypoints) > 0 and previous_keypoints is not None and len(previous_keypoints) > 0:\n","        try:\n","            differences = np.linalg.norm(previous_keypoints[0][:, :2] - pose_keypoints[0][:, :2], axis=1)\n","            if np.any(differences > 5):\n","                motion_detected = True\n","                no_motion_time = 0\n","        except ValueError:\n","            print(\"Keypoint arrays have mismatched shapes.\")\n","    else:\n","        motion_detected = True  # Assume motion if keypoints are unavailable\n","\n","    if not motion_detected:\n","        no_motion_time += frame_interval\n","    else:\n","        no_motion_time = 0\n","\n","\n","    previous_keypoints = pose_keypoints\n","\n","    risk_message = detect_risk_with_edges(pose_keypoints, bed_edges, bed_min_x, bed_max_x, bed_min_y, bed_max_y)\n","\n","    prone_contour_detected, contour_message = detect_prone_via_contour(person_mask)\n","    prone_keypoints_detected, keypoints_message = detect_prone_via_keypoints(pose_keypoints)\n","\n","    prone_detected = prone_contour_detected or prone_keypoints_detected\n","\n","    if no_motion_time >= 90 and prone_detected:\n","        choking_status = \"Choking Risk Detected!\"\n","    else:\n","        choking_status = \"Safe & Moving\"\n","\n","    mask_overlay = np.zeros_like(image, dtype=np.uint8)\n","    if bed_mask is not None:\n","        mask_overlay[mask_bool] = [255, 0, 0]\n","        if bed_min_x is not None and bed_min_y is not None:\n","            cv2.rectangle(mask_overlay, (bed_min_x, bed_min_y), (bed_max_x, bed_max_y), (255, 255, 0), 2)\n","\n","    blended_image = cv2.addWeighted(image, 0.7, mask_overlay, 0.3, 0)\n","    if pose_keypoints is not None:\n","        blended_image = draw_keypoints(blended_image, pose_keypoints[0], image.shape, pose_results[0].orig_shape)\n","        blended_image = draw_pose_skeleton(blended_image, pose_keypoints[0], pose_connections, image.shape, pose_results[0].orig_shape)\n","\n","    cv2.putText(blended_image, f\"Choke: {choking_status}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n","    cv2.putText(blended_image, f\"Fall: {risk_message}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n","    if prone_contour_detected:\n","        cv2.putText(blended_image, contour_message, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n","    elif prone_keypoints_detected:\n","        cv2.putText(blended_image, keypoints_message, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(blended_image)\n","    plt.title(f\"{os.path.basename(image_path)}\")\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","    print(f\"Processed Image: {os.path.basename(image_path)}\")\n","    print(f\"Choking Status: {choking_status}\")\n","    print(f\"Fall Status: {risk_message}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1I2s5HpvYWkk02EF8cLBjlkqOk9cOXTCL"},"id":"W31kfjzEgRf9","executionInfo":{"status":"ok","timestamp":1734070585667,"user_tz":-540,"elapsed":162210,"user":{"displayName":"bbang","userId":"09004285429129758855"}},"outputId":"69b94e6e-3e1a-47e9-e0de-c633bc43a6a2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["#### 침대 보정 함수 제거"],"metadata":{"id":"g6s3ymwZrE6e"}},{"cell_type":"code","source":["import numpy as np\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","from ultralytics import YOLO\n","\n","# YOLOv8 Segmentation 모델 로드\n","model = YOLO('/content/drive/MyDrive/Seg_dataset/best.pt')  # Segmentation 모델\n","pose_model = YOLO('yolov8n-pose.pt')\n","\n","# 테스트 이미지 경로\n","test_images_dir = '/content/test_data'\n","image_paths = [os.path.join(test_images_dir, img) for img in sorted(os.listdir(test_images_dir)) if img.endswith(('.jpg', '.png'))]\n","\n","# COCO Keypoint 연결 정의\n","pose_connections = [\n","    (0, 1), (0, 2), (1, 3), (2, 4),  # 머리 연결\n","    (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # 팔 연결\n","    (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # 다리 연결\n","]\n","\n","# 빠대 시각화 함수\n","def draw_pose_skeleton(image, keypoints, connections, img_shape, orig_shape):\n","    for connection in connections:\n","        start_idx, end_idx = connection\n","        if start_idx >= len(keypoints) or end_idx >= len(keypoints):\n","            continue\n","\n","        start_x, start_y, start_conf = keypoints[start_idx]\n","        end_x, end_y, end_conf = keypoints[end_idx]\n","        if start_conf < 0.5 or end_conf < 0.5:  # 신리도가 낮으면 사롭\n","            continue\n","\n","        start_x = int(start_x * (img_shape[1] / orig_shape[1]))\n","        start_y = int(start_y * (img_shape[0] / orig_shape[0]))\n","        end_x = int(end_x * (img_shape[1] / orig_shape[1]))\n","        end_y = int(end_y * (img_shape[0] / orig_shape[0]))\n","\n","        cv2.line(image, (start_x, start_y), (end_x, end_y), (0, 255, 255), 2)  # 노란색 선\n","\n","    return image\n","\n","# 키포인트 시각화 함수\n","def draw_keypoints(image, keypoints, img_shape, orig_shape):\n","    for keypoint in keypoints:\n","        x, y, conf = keypoint\n","        if conf > 0.5:\n","            x_original = int(x * (img_shape[1] / orig_shape[1]))\n","            y_original = int(y * (img_shape[0] / orig_shape[0]))\n","            cv2.circle(image, (x_original, y_original), 5, (0, 255, 0), -1)  # 초른색 점\n","    return image\n","\n","# 커토를 비해 뒤집길 자세 검증\n","def detect_prone_via_contour(person_mask):\n","    if person_mask is None:\n","        return False, \"No person mask available for contour analysis.\"\n","\n","    contours, _ = cv2.findContours((person_mask > 0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    if len(contours) > 0:\n","        contour = max(contours, key=cv2.contourArea)\n","        convexity = cv2.isContourConvex(contour)\n","        if convexity:\n","            return True, \"Warning: Head contour detected as round (prone position).\"\n","    return False, \"Head contour not round (no prone detected).\"\n","\n","# 키포인트 기반 뒤집길 자세 검증\n","def detect_prone_via_keypoints(pose_keypoints):\n","    if pose_keypoints is None or len(pose_keypoints) == 0:\n","        return False, \"Pose keypoints missing or incomplete.\"\n","\n","    try:\n","        nose = pose_keypoints[0][0]\n","        left_eye = pose_keypoints[0][1]\n","        right_eye = pose_keypoints[0][2]\n","    except IndexError:\n","        return False, \"Keypoints array does not contain sufficient data.\"\n","\n","    if nose[2] < 0.5 and left_eye[2] < 0.5 and right_eye[2] < 0.5:\n","        return True, \"Warning: prone position detected!\"\n","\n","    return False, \"Lying position\"\n","\n","# 위험 검증 함수\n","def detect_risk_with_edges(pose_keypoints, bed_edges, bed_min_x, bed_max_x, bed_min_y, bed_max_y):\n","    if pose_keypoints is None or len(pose_keypoints) == 0:\n","        return \"Cannot assess risk. Missing or incomplete keypoints.\"\n","\n","    if not bed_edges:\n","        return \"Cannot assess risk. Missing bed edges.\"\n","\n","    keypoints_on_edge = 0\n","    keypoints_outside_bed = 0\n","\n","    for keypoint in pose_keypoints[0]:\n","        x, y, conf = keypoint\n","        if conf < 0.5:\n","            continue\n","\n","        x_original = int(x)\n","        y_original = int(y)\n","\n","        if [x_original, y_original] in bed_edges:\n","            keypoints_on_edge += 1\n","\n","        if not (bed_min_x <= x_original <= bed_max_x and bed_min_y <= y_original <= bed_max_y):\n","            keypoints_outside_bed += 1\n","\n","    if keypoints_outside_bed >= 2:\n","        return f\"Risk Level 2: {keypoints_outside_bed} keypoints are outside the bed.\"\n","    if keypoints_on_edge > 0:\n","        return f\"Risk Level 1: {keypoints_on_edge} keypoints are exactly on the bed edge.\"\n","\n","    return \"No risk detected.\"\n","\n","# 움직임 검증 변수 초기화\n","previous_keypoints = None\n","no_motion_time = 0\n","frame_interval = 1 / 30\n","\n","# 테스트 실행\n","for image_path in image_paths:\n","    image = cv2.imread(image_path)\n","    if image is None:\n","        print(f\"Error: Unable to load image {image_path}\")\n","        continue\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    try:\n","        seg_results = model(image, conf=0.5, iou=0.4)\n","        pose_results = pose_model(image)\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        continue\n","\n","    masks = seg_results[0].masks.data.cpu().numpy() if seg_results[0].masks is not None else []\n","    pose_keypoints = pose_results[0].keypoints.data.cpu().numpy() if pose_results[0].keypoints is not None else None\n","\n","    bed_class_id = 1\n","    person_class_id = 0\n","    bed_mask = None\n","    person_mask = None\n","\n","    if seg_results[0].boxes is not None:\n","        classes = seg_results[0].boxes.cls.cpu().numpy()\n","        for i, cls in enumerate(classes):\n","            if cls == bed_class_id:\n","                bed_mask = masks[i]\n","            elif cls == person_class_id:\n","                person_mask = masks[i]\n","\n","    bed_edges = []\n","    bed_min_x = bed_max_x = bed_min_y = bed_max_y = None\n","    if bed_mask is not None:\n","        bed_mask_resized = cv2.resize(bed_mask, (image.shape[1], image.shape[0]))\n","        mask_bool = bed_mask_resized > 0.5\n","        bed_edges = extract_bed_edges(mask_bool)\n","        bed_coords = np.argwhere(mask_bool)\n","        if bed_coords.size > 0:\n","            bed_min_y, bed_max_y = np.min(bed_coords[:, 0]), np.max(bed_coords[:, 0])\n","            bed_min_x, bed_max_x = np.min(bed_coords[:, 1]), np.max(bed_coords[:, 1])\n","\n","    motion_detected = False\n","    if pose_keypoints is not None and len(pose_keypoints) > 0 and previous_keypoints is not None and len(previous_keypoints) > 0:\n","        try:\n","            differences = np.linalg.norm(previous_keypoints[0][:, :2] - pose_keypoints[0][:, :2], axis=1)\n","            if np.any(differences > 5):\n","                motion_detected = True\n","                no_motion_time = 0\n","        except ValueError:\n","            print(\"Keypoint arrays have mismatched shapes.\")\n","    else:\n","        motion_detected = True  # Assume motion if keypoints are unavailable\n","\n","    if not motion_detected:\n","        no_motion_time += frame_interval\n","    else:\n","        no_motion_time = 0\n","\n","\n","    previous_keypoints = pose_keypoints\n","\n","    risk_message = detect_risk_with_edges(pose_keypoints, bed_edges, bed_min_x, bed_max_x, bed_min_y, bed_max_y)\n","\n","    prone_contour_detected, contour_message = detect_prone_via_contour(person_mask)\n","    prone_keypoints_detected, keypoints_message = detect_prone_via_keypoints(pose_keypoints)\n","\n","    prone_detected = prone_contour_detected or prone_keypoints_detected\n","\n","    if no_motion_time >= 90 and prone_detected:\n","        choking_status = \"Choking Risk Detected!\"\n","    else:\n","        choking_status = \"Safe & Moving\"\n","\n","    mask_overlay = np.zeros_like(image, dtype=np.uint8)\n","    if bed_mask is not None:\n","        mask_overlay[mask_bool] = [255, 0, 0]\n","        if bed_min_x is not None and bed_min_y is not None:\n","            cv2.rectangle(mask_overlay, (bed_min_x, bed_min_y), (bed_max_x, bed_max_y), (255, 255, 0), 2)\n","\n","    blended_image = cv2.addWeighted(image, 0.7, mask_overlay, 0.3, 0)\n","    if pose_keypoints is not None:\n","        blended_image = draw_keypoints(blended_image, pose_keypoints[0], image.shape, pose_results[0].orig_shape)\n","        blended_image = draw_pose_skeleton(blended_image, pose_keypoints[0], pose_connections, image.shape, pose_results[0].orig_shape)\n","\n","    cv2.putText(blended_image, f\"Choke: {choking_status}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n","    cv2.putText(blended_image, f\"Fall: {risk_message}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n","    if prone_contour_detected:\n","        cv2.putText(blended_image, contour_message, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n","    elif prone_keypoints_detected:\n","        cv2.putText(blended_image, keypoints_message, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(blended_image)\n","    plt.title(f\"{os.path.basename(image_path)}\")\n","    plt.axis(\"off\")\n","    plt.show()\n","\n","    print(f\"Processed Image: {os.path.basename(image_path)}\")\n","    print(f\"Choking Status: {choking_status}\")\n","    print(f\"Fall Status: {risk_message}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1TVVL5DMcNMicsCSAA-cU_9uJpjL1MTVj"},"id":"oXESNjB9hpft","executionInfo":{"status":"ok","timestamp":1734073144117,"user_tz":-540,"elapsed":179123,"user":{"displayName":"bbang","userId":"09004285429129758855"}},"outputId":"79a2d5fd-2b51-426e-b6a6-36ddb4af3eaf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["import shutil\n","\n","# Google Drive 경로\n","google_drive_path = '/content/drive/MyDrive/test_data'\n","\n","# Local 경로에서 Google Drive로 이동\n","local_test_data_path = '/content/test_data'\n","\n","# test_data 폴더를 Google Drive로 복사\n","shutil.copytree(local_test_data_path, google_drive_path)\n","\n","print(f\"Files have been moved to {google_drive_path}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YbkB4ldF1eMD","executionInfo":{"status":"ok","timestamp":1734073605346,"user_tz":-540,"elapsed":1836,"user":{"displayName":"bbang","userId":"09004285429129758855"}},"outputId":"6e049d7f-c989-4288-e1d4-dac3290ea6bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files have been moved to /content/drive/MyDrive/test_data\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["lrW84cnZU1le","6AtFiC61jiiJ","odYF1AYFjoGo"],"gpuType":"T4","machine_shape":"hm","provenance":[],"mount_file_id":"1xJSiQJTTfxFP377f5nfvm9HqlQuVrfzM","authorship_tag":"ABX9TyPTTvlebG05lF5H1qf5MFhx"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}